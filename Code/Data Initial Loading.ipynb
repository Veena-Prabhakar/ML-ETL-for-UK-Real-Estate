{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "030c7e5a-1cdf-4784-aaa9-f36df53f0d13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:38:43.323673Z",
     "iopub.status.busy": "2024-09-12T12:38:43.322674Z",
     "iopub.status.idle": "2024-09-12T12:38:49.114141Z",
     "shell.execute_reply": "2024-09-12T12:38:49.114141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\users\\mailv\\anaconda3\\lib\\site-packages (2.0.25)\n",
      "Requirement already satisfied: psycopg2 in c:\\users\\mailv\\anaconda3\\lib\\site-packages (2.9.9)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\mailv\\anaconda3\\lib\\site-packages (from sqlalchemy) (4.9.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\mailv\\anaconda3\\lib\\site-packages (from sqlalchemy) (3.0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in c:\\users\\mailv\\anaconda3\\lib\\site-packages (2.9.9)\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages for interacting with PostgreSQL databases via SQLAlchemy\n",
    "! pip install sqlalchemy psycopg2\n",
    "# Install the psycopg2-binary package for PostgreSQL database connectivity\n",
    "! pip install psycopg2-binary\n",
    "\n",
    "import pandas as pd  # Importing Pandas provides powerful data structures for data analysis\n",
    "\n",
    "import psycopg2  # Importing PostgreSQL database adapter for Python\n",
    "from contextlib import contextmanager  # Importing contextmanager for creating context managers\n",
    "from datetime import datetime  # Importing datetime for handling date and time data\n",
    "from sqlalchemy import create_engine  # Importing create_engine for database connection engines from SQLAlchemy\n",
    "import logging  # Importing Logging module for event tracking and debugging\n",
    "import os  #Importing OS module for interacting with the operating system\n",
    "import warnings  # Warnings module to control warning messages\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c10de28-059b-41b5-9738-e4ac5cf98ee3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:38:49.116281Z",
     "iopub.status.busy": "2024-09-12T12:38:49.116281Z",
     "iopub.status.idle": "2024-09-12T12:38:49.120241Z",
     "shell.execute_reply": "2024-09-12T12:38:49.120241Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "notebook_name = 'Data Initial Loading' \n",
    "\n",
    "# Paths for the log directories\n",
    "info_log_path = f'../Logs/info/{notebook_name}_info.log'\n",
    "\n",
    "# Creating directories if they don't exist\n",
    "os.makedirs(os.path.dirname(info_log_path), exist_ok=True)\n",
    "\n",
    "# Clearing any previous handlers if re-running this setup\n",
    "logger = logging.getLogger()\n",
    "while logger.handlers:\n",
    "    logger.handlers.pop()\n",
    "\n",
    "# Configuring logging\n",
    "info_logger = logging.getLogger('info_logger')\n",
    "\n",
    "info_handler = logging.FileHandler(info_log_path, mode='a')  # Append mode\n",
    "\n",
    "info_handler.setLevel(logging.INFO)\n",
    "\n",
    "# Consistent formatter for both handlers\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "info_handler.setFormatter(formatter)\n",
    "\n",
    "# Adding handlers to the loggers\n",
    "info_logger.addHandler(info_handler)\n",
    "\n",
    "info_logger.setLevel(logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a92067bc-c2f8-4264-bcf0-247d25d2b89e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:38:49.121627Z",
     "iopub.status.busy": "2024-09-12T12:38:49.121627Z",
     "iopub.status.idle": "2024-09-12T12:38:53.178203Z",
     "shell.execute_reply": "2024-09-12T12:38:53.177121Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Loading the final selected features details from the saved Excel file\n",
    "final_selected_features_details = pd.read_excel('../Data/Output/processed_selected_features.xlsx')\n",
    "\n",
    "# Loading the data from the saved Excel file for loading into database\n",
    "data_load_df = pd.read_excel('../Data/Output/Processed_data_load_df.xlsx')\n",
    "\n",
    "info_logger.info(\"Reading Transformed data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dd0f56-9d83-4e9b-a4a2-a68576b49b56",
   "metadata": {},
   "source": [
    "### Data Mart Setup with Fact and Dimension Table creations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7ba032e-0fc8-4392-b706-59a16847eb5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:38:53.185768Z",
     "iopub.status.busy": "2024-09-12T12:38:53.185768Z",
     "iopub.status.idle": "2024-09-12T12:38:53.706578Z",
     "shell.execute_reply": "2024-09-12T12:38:53.705472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Tables dropped if existed\n",
      "Partitioning deleted if existed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created all facts and dimension table.\n",
      "Partitioning condition added in sales_transactions_fact\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configuration for database connection\n",
    "DB_CREDENTIALS = {\n",
    "    'dbname': 'UK Real Estate DB',\n",
    "    'user': 'postgres',\n",
    "    'password': '123!@*qweQWE',\n",
    "    'host': 'localhost', \n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "def main():\n",
    "    # Connecting to PostgreSQL database\n",
    "    connection = psycopg2.connect(\n",
    "        dbname=DB_CREDENTIALS['dbname'],\n",
    "        user=DB_CREDENTIALS['user'],\n",
    "        password=DB_CREDENTIALS['password'],\n",
    "        host=DB_CREDENTIALS['host'],\n",
    "        port=DB_CREDENTIALS['port']\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Dropping tables if it exists\n",
    "    try:\n",
    "        cursor.execute(\"\"\"\n",
    "            DROP TABLE IF EXISTS metadata; \n",
    "            DROP TABLE IF EXISTS sales_transactions_fact CASCADE;\n",
    "            DROP TABLE IF EXISTS district_dimension CASCADE;\n",
    "            DROP TABLE IF EXISTS property_type_dimension CASCADE;\n",
    "            DROP TABLE IF EXISTS region_dimension CASCADE;\n",
    "            DROP TABLE IF EXISTS date_dimension CASCADE;\n",
    "            DROP TABLE IF EXISTS demographics_dimension CASCADE;\n",
    "            DROP TABLE IF EXISTS education_employment_dimension CASCADE;\n",
    "            DROP TABLE IF EXISTS rental_dimension CASCADE;\n",
    "            DROP TABLE IF EXISTS vehicle_dimension CASCADE;\n",
    "        \"\"\")\n",
    "        print(\"All Tables dropped if existed\")\n",
    "        \n",
    "        # droping partition if exists\n",
    "        cursor.execute(\"\"\"\n",
    "            DO $$\n",
    "            DECLARE\n",
    "                partition RECORD;\n",
    "            BEGIN\n",
    "                FOR partition IN\n",
    "                    SELECT inhrelid::regclass AS partition_name\n",
    "                    FROM pg_inherits\n",
    "                    JOIN pg_class ON pg_class.oid = inhrelid\n",
    "                    WHERE pg_class.relnamespace = 'public'::regnamespace\n",
    "                    AND pg_class.relname LIKE 'sales_transactions_fact%'\n",
    "                LOOP\n",
    "                    EXECUTE format('DROP TABLE IF EXISTS %I CASCADE', partition.partition_name);\n",
    "                END LOOP;\n",
    "            END $$;\n",
    "        \"\"\")\n",
    "        print(\"Partitioning deleted if existed\")\n",
    "        \n",
    "        # Executing Create table DDL statements for all Dimensions and Fact table\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE region_dimension (\n",
    "                region_id SERIAL PRIMARY KEY,\n",
    "                region_code VARCHAR(255),\n",
    "                region_name VARCHAR(255),\n",
    "                local_authority_code VARCHAR(255) UNIQUE,  -- SCD Type 1: unique based on local authority code\n",
    "                local_authority_name VARCHAR(255)\n",
    "            );\n",
    "            \n",
    "            CREATE TABLE date_dimension (\n",
    "                date_key SERIAL PRIMARY KEY,\n",
    "                date DATE,   -- SCD Type 0\n",
    "                month INT,\n",
    "                quarter INT,\n",
    "                year INT,\n",
    "                transfer_month_year VARCHAR(255)  \n",
    "            );\n",
    "            \n",
    "            CREATE TABLE vehicle_dimension (\n",
    "                vehicle_id SERIAL PRIMARY KEY,\n",
    "                local_authority_code VARCHAR(255),  -- SCD Type 1: unique based on local authority code\n",
    "                region_id INT REFERENCES region_dimension(region_id),\n",
    "                buses_total FLOAT,\n",
    "                petrol_cars_total FLOAT,\n",
    "                hgv_total FLOAT,\n",
    "                petrol_lgv_total FLOAT,\n",
    "                lpg_lgv_total FLOAT,             \n",
    "                hgv_motorways FLOAT,             \n",
    "                personal_transport FLOAT         \n",
    "            );\n",
    "            \n",
    "            CREATE TABLE district_dimension (\n",
    "                district_id SERIAL PRIMARY KEY,\n",
    "                local_authority_code VARCHAR(255),\n",
    "                date DATE,\n",
    "                district VARCHAR(255),\n",
    "                town_city VARCHAR(255),\n",
    "                county VARCHAR(255),\n",
    "                start_date TIMESTAMP,  -- SCD Type 2: Start date of the record validity\n",
    "                end_date TIMESTAMP,    -- SCD Type 2: End date of the record validity (NULL if current)\n",
    "                is_current BOOLEAN DEFAULT TRUE,  -- SCD Type 2: Flag for active record\n",
    "                UNIQUE (local_authority_code, date)  -- Ensure uniqueness per local authority per month-year\n",
    "            );\n",
    "            \n",
    "            CREATE TABLE property_type_dimension (\n",
    "                property_type_id SERIAL PRIMARY KEY,\n",
    "                local_authority_code VARCHAR(255),\n",
    "                date DATE,\n",
    "                property_type VARCHAR(255),\n",
    "                duration VARCHAR(255),  \n",
    "                detached_price FLOAT,  \n",
    "                semi_detached_price FLOAT,  \n",
    "                terraced_price FLOAT,  \n",
    "                flat_price FLOAT,  \n",
    "                start_date TIMESTAMP,  -- SCD Type 2: Start date of the record validity\n",
    "                end_date TIMESTAMP,    -- SCD Type 2: End date of the record validity (NULL if current)\n",
    "                is_current BOOLEAN DEFAULT TRUE,  -- SCD Type 2: Flag for active record\n",
    "                UNIQUE (local_authority_code, date)  -- Ensure uniqueness per local authority per month-year\n",
    "            );\n",
    "            \n",
    "            CREATE TABLE education_employment_dimension (\n",
    "                education_employment_id SERIAL PRIMARY KEY,\n",
    "                local_authority_code VARCHAR(255),  \n",
    "                date DATE,\n",
    "                qualification_index_score FLOAT,\n",
    "                qualification_index_rank FLOAT,  \n",
    "                no_qualifications FLOAT,  \n",
    "                level_1_and_entry_level_qualifications FLOAT, \n",
    "                level_2_qualifications FLOAT,  \n",
    "                level_3_qualifications FLOAT, \n",
    "                apprenticeship FLOAT,  \n",
    "                level_4_qualifications_and_above FLOAT,  \n",
    "                other_qualifications FLOAT,  \n",
    "                num_aged_16_plus_unemployed FLOAT, \n",
    "                num_aged_16_plus_employed FLOAT, \n",
    "                num_aged_16_plus_self_employed FLOAT, \n",
    "                deprivation_average_score FLOAT,\n",
    "                deprivation_employment_ratio FLOAT,\n",
    "                qualification_adjusted_employment_rate FLOAT,\n",
    "                start_date TIMESTAMP,  -- SCD Type 2: Start date of the record validity\n",
    "                end_date TIMESTAMP,    -- SCD Type 2: End date of the record validity (NULL if current)\n",
    "                is_current BOOLEAN DEFAULT TRUE,  -- SCD Type 2: Flag for active record\n",
    "                UNIQUE (local_authority_code, date)  -- Ensure uniqueness per local authority per month-year\n",
    "            );\n",
    "            \n",
    "            CREATE TABLE demographics_dimension (\n",
    "                demographics_id SERIAL PRIMARY KEY,\n",
    "                local_authority_code VARCHAR(255), \n",
    "                date DATE,\n",
    "                area_sq_km FLOAT,  \n",
    "                age_0_20 FLOAT,  \n",
    "                age_20_40 FLOAT, \n",
    "                age_40_60 FLOAT,  \n",
    "                age_60_plus FLOAT,  \n",
    "                female_population FLOAT,  \n",
    "                all_ages FLOAT, \n",
    "                male_population FLOAT, \n",
    "                est_num_households_with_child FLOAT,  \n",
    "                age_dependency_ratio FLOAT, \n",
    "                start_date TIMESTAMP,  -- SCD Type 2: Start date of the record validity\n",
    "                end_date TIMESTAMP,    -- SCD Type 2: End date of the record validity (NULL if current)\n",
    "                is_current BOOLEAN DEFAULT TRUE,  -- SCD Type 2: Flag for active record\n",
    "                UNIQUE (local_authority_code, date)  -- Ensure uniqueness per local authority per month-year\n",
    "            );\n",
    "            \n",
    "            CREATE TABLE rental_dimension (\n",
    "                rental_id SERIAL PRIMARY KEY,\n",
    "                local_authority_code VARCHAR(255),\n",
    "                date DATE,\n",
    "                rental_price FLOAT,\n",
    "                one_bedroom_rent FLOAT,\n",
    "                two_bedrooms_rent FLOAT,\n",
    "                three_bedrooms_rent FLOAT,  \n",
    "                four_or_more_bedrooms_rent FLOAT, \n",
    "                all_categories_rent FLOAT,\n",
    "                start_date TIMESTAMP,  -- SCD Type 2: Start date of the record validity\n",
    "                end_date TIMESTAMP,    -- SCD Type 2: End date of the record validity (NULL if current)\n",
    "                is_current BOOLEAN DEFAULT TRUE,  -- SCD Type 2: Flag for active record\n",
    "                UNIQUE (local_authority_code, date)  -- Ensure uniqueness per local authority per month-year\n",
    "            );\n",
    "            \n",
    "            CREATE TABLE sales_transactions_fact (\n",
    "                sales_id SERIAL,\n",
    "                local_authority_code VARCHAR(255),\n",
    "                date DATE,\n",
    "                district_id INT REFERENCES district_dimension(district_id),\n",
    "                region_id INT REFERENCES region_dimension(region_id),\n",
    "                property_type_id INT REFERENCES property_type_dimension(property_type_id),\n",
    "                vehicle_id INT REFERENCES vehicle_dimension(vehicle_id),\n",
    "                rental_id INT REFERENCES rental_dimension(rental_id),\n",
    "                demographics_id INT REFERENCES demographics_dimension(demographics_id),\n",
    "                education_employment_id INT REFERENCES education_employment_dimension(education_employment_id),\n",
    "                date_key INT REFERENCES date_dimension(date_key),\n",
    "                price NUMERIC,\n",
    "                average_price FLOAT,\n",
    "                predicted_price_unscaled FLOAT,\n",
    "                index FLOAT,\n",
    "                average_price_pct_change FLOAT,\n",
    "                annual_change_percent FLOAT,\n",
    "                new_price FLOAT,\n",
    "                old_price FLOAT,\n",
    "                sales_volume FLOAT,\n",
    "                sales_volume_log FLOAT,\n",
    "                old_sales_volume FLOAT,\n",
    "                detached_flat_ratio FLOAT,\n",
    "                detached_terraced_ratio FLOAT,\n",
    "                semi_detached_price_pct_change FLOAT,\n",
    "                detached_semi_detached_ratio FLOAT,\n",
    "                detached_price_log FLOAT,\n",
    "                semi_detached_price_log FLOAT,\n",
    "                flat_price_log FLOAT,\n",
    "                terraced_price_pct_change FLOAT,\n",
    "                terraced_price_log FLOAT,\n",
    "                gdhi FLOAT,\n",
    "                deprivation_adjusted_gdhi FLOAT,\n",
    "                gdhi_per_capita FLOAT,\n",
    "                foo_price FLOAT,\n",
    "                cash_price FLOAT,\n",
    "                mortgage_price FLOAT,\n",
    "                housing_demand_indicator FLOAT,\n",
    "                deprivation_reduction_potential FLOAT,\n",
    "                flat_price_pct_change FLOAT,  -- Added new field\n",
    "                detached_price_pct_change FLOAT,  -- Added new field\n",
    "                average_price_log FLOAT,  -- Added new field\n",
    "                ftb_price FLOAT,  -- Added new field\n",
    "                start_date TIMESTAMP,  -- SCD Type 2: Start date of the record validity\n",
    "                end_date TIMESTAMP,    -- SCD Type 2: End date of the record validity (NULL if current)\n",
    "                is_current BOOLEAN DEFAULT TRUE,  -- SCD Type 2: Flag for active record\n",
    "                PRIMARY KEY (sales_id, local_authority_code, date)  -- Ensure uniqueness per local authority per month-year\n",
    "            )PARTITION BY RANGE (date);\n",
    "            \n",
    "            \n",
    "            CREATE TABLE metadata (\n",
    "                id SERIAL PRIMARY KEY,\n",
    "                table_name VARCHAR(255),\n",
    "                last_extracted_date TIMESTAMP WITHOUT TIME ZONE,\n",
    "                scd_type INTEGER, \n",
    "                last_modified_date TIMESTAMP WITHOUT TIME ZONE,\n",
    "                created_date TIMESTAMP WITHOUT TIME ZONE\n",
    "            );\n",
    "\n",
    "\n",
    "        \"\"\")\n",
    "        print(\"Created all facts and dimension table.\")\n",
    "        cursor.execute(\"\"\"\n",
    "            -- January 2023\n",
    "            CREATE TABLE sales_transactions_fact_2023_01 PARTITION OF sales_transactions_fact\n",
    "                FOR VALUES FROM ('2023-01-01') TO ('2023-02-01');\n",
    "            \n",
    "            -- February 2023\n",
    "            CREATE TABLE sales_transactions_fact_2023_02 PARTITION OF sales_transactions_fact\n",
    "                FOR VALUES FROM ('2023-02-01') TO ('2023-03-01');\n",
    "            \n",
    "            -- March 2023\n",
    "            CREATE TABLE sales_transactions_fact_2023_03 PARTITION OF sales_transactions_fact\n",
    "                FOR VALUES FROM ('2023-03-01') TO ('2023-04-01');\n",
    "            \n",
    "            -- April 2023\n",
    "            CREATE TABLE sales_transactions_fact_2023_04 PARTITION OF sales_transactions_fact\n",
    "                FOR VALUES FROM ('2023-04-01') TO ('2023-05-01');\n",
    "            \n",
    "            -- May 2023\n",
    "            CREATE TABLE sales_transactions_fact_2023_05 PARTITION OF sales_transactions_fact\n",
    "                FOR VALUES FROM ('2023-05-01') TO ('2023-06-01');\n",
    "            \n",
    "            -- June 2023\n",
    "            CREATE TABLE sales_transactions_fact_2023_06 PARTITION OF sales_transactions_fact\n",
    "                FOR VALUES FROM ('2023-06-01') TO ('2023-07-01');\n",
    "            \n",
    "            -- July 2023\n",
    "            CREATE TABLE sales_transactions_fact_2023_07 PARTITION OF sales_transactions_fact\n",
    "                FOR VALUES FROM ('2023-07-01') TO ('2023-08-01');\n",
    "            \n",
    "            -- August 2023\n",
    "            CREATE TABLE sales_transactions_fact_2023_08 PARTITION OF sales_transactions_fact\n",
    "                FOR VALUES FROM ('2023-08-01') TO ('2023-09-01');\n",
    "            \n",
    "            -- September 2023\n",
    "            CREATE TABLE sales_transactions_fact_2023_09 PARTITION OF sales_transactions_fact\n",
    "                FOR VALUES FROM ('2023-09-01') TO ('2023-10-01');\n",
    "            \n",
    "            -- October 2023\n",
    "            CREATE TABLE sales_transactions_fact_2023_10 PARTITION OF sales_transactions_fact\n",
    "                FOR VALUES FROM ('2023-10-01') TO ('2023-11-01');\n",
    "            \n",
    "            -- November 2023\n",
    "            CREATE TABLE sales_transactions_fact_2023_11 PARTITION OF sales_transactions_fact\n",
    "                FOR VALUES FROM ('2023-11-01') TO ('2023-12-01');\n",
    "            \n",
    "            -- December 2023\n",
    "            CREATE TABLE sales_transactions_fact_2023_12 PARTITION OF sales_transactions_fact\n",
    "                FOR VALUES FROM ('2023-12-01') TO ('2024-01-01');\n",
    "\n",
    "            -- January 2024\n",
    "            CREATE TABLE sales_transactions_fact_2024_01 PARTITION OF sales_transactions_fact\n",
    "                FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');\n",
    "            \n",
    "            -- February 2024\n",
    "            CREATE TABLE sales_transactions_fact_2024_02 PARTITION OF sales_transactions_fact\n",
    "                FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');\n",
    "        \"\"\")\n",
    "        print(\"Partitioning condition added in sales_transactions_fact\")\n",
    "\n",
    "    except psycopg2.Error as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "        connection.rollback()  # Rollback in case of error\n",
    "    else:\n",
    "        connection.commit()  # Commit the changes if all is well\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    print(\"Database connection closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "info_logger.info(\"Created all Fact table and Dimension Tables along with required Partitioning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab017d4d-5415-4c92-85e3-094d6262f8ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:38:53.711601Z",
     "iopub.status.busy": "2024-09-12T12:38:53.710478Z",
     "iopub.status.idle": "2024-09-12T12:38:53.775169Z",
     "shell.execute_reply": "2024-09-12T12:38:53.774163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped tables if existed\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configuration for database connection\n",
    "DB_CREDENTIALS = {\n",
    "    'dbname': 'UK Real Estate DB',\n",
    "    'user': 'postgres',\n",
    "    'password': '123!@*qweQWE',\n",
    "    'host': 'localhost', \n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "def main():\n",
    "    # Connect to PostgreSQL database\n",
    "    connection = psycopg2.connect(\n",
    "        dbname=DB_CREDENTIALS['dbname'],\n",
    "        user=DB_CREDENTIALS['user'],\n",
    "        password=DB_CREDENTIALS['password'],\n",
    "        host=DB_CREDENTIALS['host'],\n",
    "        port=DB_CREDENTIALS['port']\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Dropping additional tables if already exists\n",
    "    try:\n",
    "        cursor.execute(\"\"\"\n",
    "            DROP TABLE IF EXISTS feature_importance_dimension; \n",
    "\t\t\tDROP TABLE IF EXISTS governance_table; \n",
    "\t\t\tDROP TABLE IF EXISTS initial_load_etl_source_data; \n",
    "\t\t\tDROP TABLE IF EXISTS incremental_load_etl_source_data; \n",
    "        \"\"\")\n",
    "        print(\"Dropped tables if existed\")\n",
    "        \n",
    "    except psycopg2.Error as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "        connection.rollback()  # Rollback in case of error\n",
    "    else:\n",
    "        connection.commit()  # Commit the changes if all is well\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    print(\"Database connection closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff5d2df-43f7-4125-a831-bae2edad9df1",
   "metadata": {},
   "source": [
    "### Processing additional tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73363687-eb0a-4a51-ba67-43bdb0fe0f5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:38:53.778169Z",
     "iopub.status.busy": "2024-09-12T12:38:53.778169Z",
     "iopub.status.idle": "2024-09-12T12:38:59.960092Z",
     "shell.execute_reply": "2024-09-12T12:38:59.957971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_importance_dimension loaded successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "governance_table loaded successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_load loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configuration for database connection\n",
    "DB_CREDENTIALS = {\n",
    "    'user': 'postgres',\n",
    "    'password': '123%21%40*qweQWE',\n",
    "    'host': 'localhost', \n",
    "    'port': '5432',  \n",
    "    'dbname': 'UK Real Estate DB'\n",
    "}\n",
    "\n",
    "def create_db_engine(credentials):\n",
    "    \"\"\"\n",
    "    Create and return a SQLAlchemy engine for connecting to PostgreSQL.\n",
    "    \"\"\"\n",
    "    connection_string = (\n",
    "        f\"postgresql+psycopg2://{credentials['user']}:{credentials['password']}@\"\n",
    "        f\"{credentials['host']}:{credentials['port']}/{credentials['dbname']}\"\n",
    "    )\n",
    "    return create_engine(connection_string)\n",
    "\n",
    "def calculate_feature_importance(df):\n",
    "    \"\"\"\n",
    "    Calculate and add percentage importance to the DataFrame.\n",
    "    \"\"\"\n",
    "    total_importance = df['importance'].sum()\n",
    "    df['importance_percentage'] = (df['importance'] / total_importance) * 100\n",
    "    df['importance_percentage'] = df['importance_percentage'].round(2)\n",
    "    return df\n",
    "\n",
    "def save_to_postgresql(df, table_name, engine):\n",
    "    \"\"\"\n",
    "    Save the DataFrame to a PostgreSQL table.\n",
    "    \"\"\"\n",
    "    df.to_sql(table_name, engine, index=False, if_exists='replace')\n",
    "\n",
    "def load_feature_importance(file_path, engine):\n",
    "    \"\"\"\n",
    "    Load the feature importance data from an Excel file, process it, and save it to PostgreSQL.\n",
    "    \"\"\"\n",
    "    feature_importance_df = pd.read_excel(file_path)\n",
    "    processed_feature_df = calculate_feature_importance(feature_importance_df)\n",
    "    save_to_postgresql(processed_feature_df, 'feature_importance_dimension', engine)\n",
    "\n",
    "def load_governance_table(excel_path, engine):\n",
    "    \"\"\"\n",
    "    Load data from the Excel file into a DataFrame and save it to PostgreSQL.\n",
    "    \"\"\"\n",
    "    governance_table = pd.read_excel(excel_path)\n",
    "    save_to_postgresql(governance_table, 'governance_table', engine)\n",
    "\n",
    "def load_data_load(excel_path, engine):\n",
    "    \"\"\"\n",
    "    Load data from an Excel file into a DataFrame and save it to PostgreSQL.\n",
    "    \"\"\"\n",
    "    data_load = pd.read_excel(excel_path)\n",
    "    save_to_postgresql(data_load, 'initial_load_etl_source_data', engine)\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to orchestrate the data loading and processing tasks.\n",
    "    \"\"\"\n",
    "    # Paths to data files\n",
    "    feature_importance_path = '../Data/Output/processed_selected_features.xlsx'\n",
    "    governance_excel_path = '../Data/Input/governance_table.xlsx'\n",
    "    data_load_path = '../Data/Output/Processed_data_load_df.xlsx'\n",
    "\n",
    "    # Creating database engine\n",
    "    engine = create_db_engine(DB_CREDENTIALS)\n",
    "\n",
    "    # Loading and processing feature importance data\n",
    "    load_feature_importance(feature_importance_path, engine)\n",
    "    print(\"feature_importance_dimension loaded successfully.\")\n",
    "\n",
    "    # Loading and saving governance table data\n",
    "    load_governance_table(governance_excel_path, engine)\n",
    "    print(\"governance_table loaded successfully.\")\n",
    "\n",
    "    # Loading and saving Initial load source table data\n",
    "    load_data_load(data_load_path, engine)\n",
    "    print(\"data_load loaded successfully.\")\n",
    "\n",
    "# Script execution entry point\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "info_logger.info(\"Loaded Governance table and Feature Importance table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f747c9f2-44da-4adc-af5d-2a598dd59fb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:38:59.963554Z",
     "iopub.status.busy": "2024-09-12T12:38:59.962468Z",
     "iopub.status.idle": "2024-09-12T12:39:00.021074Z",
     "shell.execute_reply": "2024-09-12T12:39:00.020032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'table_name' added to 'feature_importance_dimension'.\n",
      "Updated 'table_name' in 'feature_importance_dimension'.\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configuration for database connection\n",
    "DB_CREDENTIALS = {\n",
    "    'dbname': 'UK Real Estate DB',\n",
    "    'user': 'postgres',\n",
    "    'password': '123!@*qweQWE',\n",
    "    'host': 'localhost', \n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "def main():\n",
    "    # Connect to PostgreSQL database\n",
    "    connection = psycopg2.connect(\n",
    "        dbname=DB_CREDENTIALS['dbname'],\n",
    "        user=DB_CREDENTIALS['user'],\n",
    "        password=DB_CREDENTIALS['password'],\n",
    "        host=DB_CREDENTIALS['host'],\n",
    "        port=DB_CREDENTIALS['port']\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Adding new column to the feature_importance_dimension table\n",
    "    try:\n",
    "        cursor.execute(\"\"\"\n",
    "            ALTER TABLE feature_importance_dimension\n",
    "            ADD COLUMN table_name VARCHAR(255);;\n",
    "        \"\"\")\n",
    "        print(\"Column 'table_name' added to 'feature_importance_dimension'.\")\n",
    "        \n",
    "        # Updating table_name for each feature\n",
    "        cursor.execute(\"\"\"\n",
    "            UPDATE feature_importance_dimension\n",
    "            SET table_name = 'rental_dimension'\n",
    "            WHERE feature IN ('rental_price', 'all_categories_rent', 'one_bedroom_rent', 'two_bedrooms_rent', \n",
    "                              'three_bedrooms_rent', 'four_or_more_bedrooms_rent');\n",
    "\n",
    "            UPDATE feature_importance_dimension\n",
    "            SET table_name = 'demographics_dimension'\n",
    "            WHERE feature IN ('age_20_40', 'area_sq_km', 'age_60_plus', 'age_0_20', 'age_40_60', \n",
    "                              'female_population', 'male_population', 'all_ages', 'est_num_households_with_child');\n",
    "\n",
    "            UPDATE feature_importance_dimension\n",
    "            SET table_name = 'education_employment_dimension'\n",
    "            WHERE feature IN ('qualification_index_rank', 'no_qualifications', 'other_qualifications', \n",
    "                              'num_aged_16_plus_unemployed', 'num_aged_16_plus_self_employed', \n",
    "                              'qualification_index_score', 'num_aged_16_plus_employed', \n",
    "                              'deprivation_average_score', 'level_4_qualifications_and_above', \n",
    "                              'level_1_and_entry_level_qualifications', 'level_2_qualifications', \n",
    "                              'level_3_qualifications', 'apprenticeship');\n",
    "\n",
    "            UPDATE feature_importance_dimension\n",
    "            SET table_name = 'vehicle_dimension'\n",
    "            WHERE feature IN ('petrol_lgv_total', 'hgv_total', 'buses_total', 'petrol_cars_total', \n",
    "                              'lpg_lgv_total', 'hgv_motorways', 'personal_transport');\n",
    "\n",
    "            UPDATE feature_importance_dimension\n",
    "            SET table_name = 'sales_transactions_fact'\n",
    "            WHERE feature IN ('foo_price', 'detached_price', 'semi_detached_price', 'old_price', \n",
    "                              'sales_volume', 'new_price', 'cash_price', 'detached_flat_ratio', \n",
    "                              'detached_price_log', 'semi_detached_price_log', 'flat_price', \n",
    "                              'flat_price_log', 'average_price_pct_change', 'semi_detached_price_pct_change', \n",
    "                              'detached_terraced_ratio', 'detached_semi_detached_ratio', \n",
    "                              'terraced_price_pct_change', 'terraced_price_log', 'gdhi', \n",
    "                              'old_sales_volume', 'sales_volume_log', 'mortgage_price', \n",
    "                              'annual_change_percent', 'average_price', 'average_price_log', \n",
    "                              'ftb_price', 'index', 'detached_price_pct_change', 'terraced_price','flat_price_pct_change');\n",
    "\n",
    "            UPDATE feature_importance_dimension\n",
    "            SET table_name = 'region_dimension'\n",
    "            WHERE feature IN ('local_authority_code', 'region_code');\n",
    "\n",
    "            UPDATE feature_importance_dimension\n",
    "            SET table_name = 'date_dimension'\n",
    "            WHERE feature IN ('month', 'quarter');\n",
    "\n",
    "            UPDATE feature_importance_dimension\n",
    "            SET table_name = 'property_type_dimension'\n",
    "            WHERE feature IN ('property_type', 'duration');\n",
    "\n",
    "        \"\"\")\n",
    "        print(\"Updated 'table_name' in 'feature_importance_dimension'.\")\n",
    "\n",
    "    except psycopg2.Error as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "        connection.rollback()  # Rollback in case of error\n",
    "    else:\n",
    "        connection.commit()  # Commit the changes if all is well\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    print(\"Database connection closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8c65ef-9b2f-4a9a-9c53-db0f1e116a20",
   "metadata": {},
   "source": [
    "##  Initial Load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2fdb785-06cb-46a8-89b9-d08bdd55af0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:39:00.027196Z",
     "iopub.status.busy": "2024-09-12T12:39:00.027196Z",
     "iopub.status.idle": "2024-09-12T12:39:00.098061Z",
     "shell.execute_reply": "2024-09-12T12:39:00.096945Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Database credentials\n",
    "DB_CONFIG = {\n",
    "    'dbname': 'UK Real Estate DB',\n",
    "    'user': 'postgres',\n",
    "    'password': '123!@*qweQWE',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "@contextmanager\n",
    "def get_db_connection():\n",
    "    \"\"\"Context manager for PostgreSQL database connection.\"\"\"\n",
    "    connection = psycopg2.connect(**DB_CONFIG)\n",
    "    try:\n",
    "        yield connection\n",
    "    finally:\n",
    "        connection.close()\n",
    "\n",
    "def create_temp_table(cursor, table_name, schema):\n",
    "    \"\"\"Creates a temporary table.\"\"\"\n",
    "    create_query = f\"CREATE TEMPORARY TABLE {table_name} ({schema});\"\n",
    "    cursor.execute(create_query)\n",
    "\n",
    "def insert_data(cursor, table_name, columns, data_frame):\n",
    "    \"\"\"Inserts data into the temporary table.\"\"\"\n",
    "    columns_str = ', '.join(columns)\n",
    "    values_str = ', '.join(['%s'] * len(columns))\n",
    "    insert_query = f\"INSERT INTO {table_name} ({columns_str}) VALUES ({values_str});\"\n",
    "    for _, row in data_frame[columns].drop_duplicates().iterrows():\n",
    "        cursor.execute(insert_query, tuple(row))\n",
    "\n",
    "def update_existing_records(cursor, update_query):\n",
    "    \"\"\"Updates existing records in the target table.\"\"\"\n",
    "    cursor.execute(update_query)\n",
    "\n",
    "def insert_new_records(cursor, insert_query):\n",
    "    \"\"\"Inserts new records into the target table.\"\"\"\n",
    "    cursor.execute(insert_query)\n",
    "\n",
    "def drop_temp_table(cursor, table_name):\n",
    "    \"\"\"Drops the temporary table.\"\"\"\n",
    "    cursor.execute(f\"DROP TABLE {table_name};\")\n",
    "\n",
    "def load_region_dimension():\n",
    "    \"\"\"Loads data into region_dimension table.\"\"\"\n",
    "    with get_db_connection() as connection:\n",
    "        cursor = connection.cursor()\n",
    "        create_temp_table(cursor, 'region_dimension_temp',\n",
    "            'region_code VARCHAR(255), region_name VARCHAR(255), local_authority_code VARCHAR(255), local_authority_name VARCHAR(255)')\n",
    "        \n",
    "        insert_data(cursor, 'region_dimension_temp', \n",
    "                    ['region_code', 'region_name', 'local_authority_code', 'local_authority_name'], \n",
    "                    initial_load_df)\n",
    "              \n",
    "        cursor.execute(\"\"\"\n",
    "        INSERT INTO region_dimension (region_code, region_name, local_authority_code, local_authority_name)\n",
    "        SELECT temp.region_code, temp.region_name, temp.local_authority_code, temp.local_authority_name\n",
    "        FROM region_dimension_temp temp\n",
    "        LEFT JOIN region_dimension rd ON rd.local_authority_code = temp.local_authority_code\n",
    "        WHERE rd.local_authority_code IS NULL;\n",
    "        \"\"\")\n",
    "        \n",
    "        drop_temp_table(cursor, 'region_dimension_temp')\n",
    "        connection.commit()\n",
    "        print(\"Initial load for region_dimension completed.\")\n",
    "        info_logger.info(\"Initial load for region_dimension completed\")\n",
    "\n",
    "def load_date_dimension():\n",
    "    \"\"\"Loads data into date_dimension table.\"\"\"\n",
    "    with get_db_connection() as connection:\n",
    "        cursor = connection.cursor()\n",
    "        create_temp_table(cursor, 'date_dimension_temp',\n",
    "            'date DATE, month INT, quarter INT, year INT, transfer_month_year VARCHAR(255)')\n",
    "        \n",
    "        insert_data(cursor, 'date_dimension_temp', \n",
    "                    ['date', 'month', 'quarter', 'year', 'transfer_month_year'], \n",
    "                    initial_load_df)\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "        INSERT INTO date_dimension (date, month, quarter, year, transfer_month_year)\n",
    "        SELECT date, month, quarter, year, transfer_month_year\n",
    "        FROM date_dimension_temp;\n",
    "        \"\"\")\n",
    "        \n",
    "        drop_temp_table(cursor, 'date_dimension_temp')\n",
    "        connection.commit()\n",
    "        print(\"Initial load for date_dimension completed.\")\n",
    "        info_logger.info(\"Initial load for date_dimension completed\")\n",
    "        \n",
    "def load_vehicle_dimension():\n",
    "    \"\"\"Loads data into vehicle_dimension table.\"\"\"\n",
    "    with get_db_connection() as connection:\n",
    "        cursor = connection.cursor()\n",
    "        create_temp_table(cursor, 'vehicle_dimension_temp',\n",
    "            'local_authority_code VARCHAR(255), buses_total FLOAT, petrol_cars_total FLOAT, hgv_total FLOAT, petrol_lgv_total FLOAT, lpg_lgv_total FLOAT, hgv_motorways FLOAT, personal_transport FLOAT')\n",
    "        \n",
    "        insert_data(cursor, 'vehicle_dimension_temp', \n",
    "                    ['local_authority_code', 'buses_total', 'petrol_cars_total', 'hgv_total', 'petrol_lgv_total', 'lpg_lgv_total', 'hgv_motorways', 'personal_transport'], \n",
    "                    initial_load_df)\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "        INSERT INTO vehicle_dimension (local_authority_code, region_id, buses_total, petrol_cars_total, hgv_total, petrol_lgv_total, lpg_lgv_total, hgv_motorways, personal_transport)\n",
    "        SELECT temp.local_authority_code, rd.region_id, temp.buses_total, temp.petrol_cars_total, temp.hgv_total, temp.petrol_lgv_total, temp.lpg_lgv_total, temp.hgv_motorways, temp.personal_transport\n",
    "        FROM vehicle_dimension_temp temp\n",
    "        JOIN region_dimension rd ON temp.local_authority_code = rd.local_authority_code;\n",
    "        \"\"\")\n",
    "        \n",
    "        drop_temp_table(cursor, 'vehicle_dimension_temp')\n",
    "        connection.commit()\n",
    "        print(\"Initial load for vehicle_dimension completed.\")\n",
    "        info_logger.info(\"Initial load for vehicle_dimension completed\")\n",
    "        \n",
    "def load_rental_dimension():\n",
    "    \"\"\"Loads data into rental_dimension table.\"\"\"\n",
    "    with get_db_connection() as connection:\n",
    "        cursor = connection.cursor()\n",
    "        create_temp_table(cursor, 'rental_dimension_temp',\n",
    "            'local_authority_code VARCHAR(255), date DATE, rental_price FLOAT, one_bedroom_rent FLOAT, two_bedrooms_rent FLOAT, three_bedrooms_rent FLOAT, four_or_more_bedrooms_rent FLOAT, all_categories_rent FLOAT')\n",
    "        \n",
    "        insert_data(cursor, 'rental_dimension_temp',\n",
    "                    ['local_authority_code', 'date', 'rental_price', 'one_bedroom_rent', 'two_bedrooms_rent', 'three_bedrooms_rent', 'four_or_more_bedrooms_rent', 'all_categories_rent'],\n",
    "                    initial_load_df)\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "        INSERT INTO rental_dimension (local_authority_code, date, rental_price, one_bedroom_rent, two_bedrooms_rent, three_bedrooms_rent, four_or_more_bedrooms_rent, all_categories_rent, start_date, end_date, is_current)\n",
    "        SELECT temp.local_authority_code, date, temp.rental_price, temp.one_bedroom_rent, temp.two_bedrooms_rent, temp.three_bedrooms_rent, temp.four_or_more_bedrooms_rent, temp.all_categories_rent, NOW() AS start_date, NULL AS end_date, TRUE AS is_current\n",
    "        FROM (\n",
    "            SELECT temp.*, \n",
    "                   ROW_NUMBER() OVER (PARTITION BY temp.local_authority_code ORDER BY temp.date DESC) AS rn\n",
    "            FROM rental_dimension_temp temp\n",
    "        ) temp\n",
    "        WHERE temp.rn = 1;\n",
    "        \"\"\")\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "        INSERT INTO rental_dimension (local_authority_code, date, rental_price, one_bedroom_rent, two_bedrooms_rent, three_bedrooms_rent, four_or_more_bedrooms_rent, all_categories_rent, start_date, end_date, is_current)\n",
    "        SELECT temp.local_authority_code, temp.date, temp.rental_price, temp.one_bedroom_rent, temp.two_bedrooms_rent, temp.three_bedrooms_rent, temp.four_or_more_bedrooms_rent, temp.all_categories_rent, NOW() AS start_date, NOW() AS end_date, FALSE AS is_current\n",
    "        FROM (\n",
    "            SELECT temp.*, \n",
    "                   ROW_NUMBER() OVER (PARTITION BY temp.local_authority_code ORDER BY temp.date DESC) AS rn\n",
    "            FROM rental_dimension_temp temp\n",
    "        ) temp\n",
    "        WHERE temp.rn > 1;\n",
    "        \"\"\")\n",
    "        \n",
    "        drop_temp_table(cursor, 'rental_dimension_temp')\n",
    "        connection.commit()\n",
    "        print(\"Initial load for rental_dimension completed.\")\n",
    "        info_logger.info(\"Initial load for rental_dimension completed\")\n",
    "        \n",
    "def load_district_dimension():\n",
    "    \"\"\"Loads data into district_dimension table.\"\"\"\n",
    "    with get_db_connection() as connection:\n",
    "        cursor = connection.cursor()\n",
    "        create_temp_table(cursor, 'district_dimension_temp',\n",
    "            'local_authority_code VARCHAR(255), date DATE, district VARCHAR(255), town_city VARCHAR(255), county VARCHAR(255)')\n",
    "        \n",
    "        insert_data(cursor, 'district_dimension_temp',\n",
    "                    ['local_authority_code', 'date', 'district', 'town_city', 'county'],\n",
    "                    initial_load_df)\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "        INSERT INTO district_dimension (local_authority_code, date, district, town_city, county, start_date, end_date, is_current)\n",
    "        SELECT temp.local_authority_code, temp.date, temp.district, temp.town_city, temp.county, NOW() AS start_date, NULL AS end_date, TRUE AS is_current\n",
    "        FROM (\n",
    "            SELECT temp.*, \n",
    "                   ROW_NUMBER() OVER (PARTITION BY temp.local_authority_code ORDER BY temp.date DESC) AS rn\n",
    "            FROM district_dimension_temp temp\n",
    "        ) temp\n",
    "        WHERE temp.rn = 1;\n",
    "        \"\"\")\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "        INSERT INTO district_dimension (local_authority_code, date, district, town_city, county, start_date, end_date, is_current)\n",
    "        SELECT temp.local_authority_code, temp.date, temp.district, temp.town_city, temp.county, NOW() AS start_date, NOW() AS end_date, FALSE AS is_current\n",
    "        FROM (\n",
    "            SELECT temp.*, \n",
    "                   ROW_NUMBER() OVER (PARTITION BY temp.local_authority_code ORDER BY temp.date DESC) AS rn\n",
    "            FROM district_dimension_temp temp\n",
    "        ) temp\n",
    "        WHERE temp.rn > 1;\n",
    "        \"\"\")\n",
    "        \n",
    "        drop_temp_table(cursor, 'district_dimension_temp')\n",
    "        connection.commit()\n",
    "        print(\"Initial load for district_dimension completed.\")\n",
    "        info_logger.info(\"Initial load for district_dimension completed\")\n",
    "        \n",
    "def load_property_type_dimension():\n",
    "    \"\"\"Loads data into property_type_dimension table.\"\"\"\n",
    "    with get_db_connection() as connection:\n",
    "        cursor = connection.cursor()\n",
    "        create_temp_table(cursor, 'property_type_dimension_temp',\n",
    "            'local_authority_code VARCHAR(255), date DATE, property_type VARCHAR(255), duration VARCHAR(255), detached_price FLOAT, semi_detached_price FLOAT, terraced_price FLOAT, flat_price FLOAT')\n",
    "        \n",
    "        insert_data(cursor, 'property_type_dimension_temp',\n",
    "                    ['local_authority_code', 'date', 'property_type', 'duration', 'detached_price', 'semi_detached_price', 'terraced_price', 'flat_price'],\n",
    "                    initial_load_df)\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "        INSERT INTO property_type_dimension (local_authority_code, date, property_type, duration, detached_price, semi_detached_price, terraced_price, flat_price, start_date, end_date, is_current)\n",
    "        SELECT temp.local_authority_code, temp.date, temp.property_type, temp.duration, temp.detached_price, temp.semi_detached_price, temp.terraced_price, temp.flat_price, NOW() AS start_date, NULL AS end_date, TRUE AS is_current\n",
    "        FROM (\n",
    "            SELECT temp.*, \n",
    "                   ROW_NUMBER() OVER (PARTITION BY temp.local_authority_code ORDER BY temp.date DESC) AS rn\n",
    "            FROM property_type_dimension_temp temp\n",
    "        ) temp\n",
    "        WHERE temp.rn = 1;\n",
    "        \"\"\")\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "        INSERT INTO property_type_dimension (local_authority_code, date, property_type, duration, detached_price, semi_detached_price, terraced_price, flat_price, start_date, end_date, is_current)\n",
    "        SELECT temp.local_authority_code, temp.date, temp.property_type, temp.duration, temp.detached_price, temp.semi_detached_price, temp.terraced_price, temp.flat_price, NOW() AS start_date, NOW() AS end_date, FALSE AS is_current\n",
    "        FROM (\n",
    "            SELECT temp.*, \n",
    "                   ROW_NUMBER() OVER (PARTITION BY temp.local_authority_code ORDER BY temp.date DESC) AS rn\n",
    "            FROM property_type_dimension_temp temp\n",
    "        ) temp\n",
    "        WHERE temp.rn > 1;\n",
    "        \"\"\")\n",
    "        \n",
    "        drop_temp_table(cursor, 'property_type_dimension_temp')\n",
    "        connection.commit()\n",
    "        print(\"Initial load for property_type_dimension completed.\")\n",
    "        info_logger.info(\"Initial load for property_type_dimension completed\")\n",
    "                \n",
    "def load_education_employment_dimension():\n",
    "    \"\"\"Loads data into education_employment_dimension table.\"\"\"\n",
    "    with get_db_connection() as connection:\n",
    "        cursor = connection.cursor()\n",
    "        create_temp_table(cursor, 'education_employment_dimension_temp',\n",
    "            'local_authority_code VARCHAR(255), date DATE, qualification_index_score FLOAT, qualification_index_rank FLOAT, no_qualifications FLOAT, level_1_and_entry_level_qualifications FLOAT, level_2_qualifications FLOAT, level_3_qualifications FLOAT, apprenticeship FLOAT, level_4_qualifications_and_above FLOAT, other_qualifications FLOAT, num_aged_16_plus_unemployed FLOAT, num_aged_16_plus_employed FLOAT, num_aged_16_plus_self_employed FLOAT, deprivation_average_score FLOAT, deprivation_employment_ratio FLOAT, qualification_adjusted_employment_rate FLOAT')\n",
    "        \n",
    "        insert_data(cursor, 'education_employment_dimension_temp',\n",
    "                    ['local_authority_code', 'date', 'qualification_index_score', 'qualification_index_rank', 'no_qualifications', 'level_1_and_entry_level_qualifications', 'level_2_qualifications', 'level_3_qualifications', 'apprenticeship', 'level_4_qualifications_and_above', 'other_qualifications', 'num_aged_16_plus_unemployed', 'num_aged_16_plus_employed', 'num_aged_16_plus_self_employed', 'deprivation_average_score', 'deprivation_employment_ratio', 'qualification_adjusted_employment_rate'],\n",
    "                    initial_load_df)\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "        INSERT INTO education_employment_dimension (local_authority_code, date, qualification_index_score, \n",
    "            qualification_index_rank, no_qualifications, level_1_and_entry_level_qualifications, level_2_qualifications, \n",
    "            level_3_qualifications, apprenticeship, level_4_qualifications_and_above, other_qualifications, \n",
    "            num_aged_16_plus_unemployed, num_aged_16_plus_employed, num_aged_16_plus_self_employed, \n",
    "            deprivation_average_score, deprivation_employment_ratio, qualification_adjusted_employment_rate, \n",
    "            start_date, end_date, is_current)\n",
    "        SELECT temp.local_authority_code, temp.date, temp.qualification_index_score, temp.qualification_index_rank, \n",
    "            temp.no_qualifications, temp.level_1_and_entry_level_qualifications, temp.level_2_qualifications, \n",
    "            temp.level_3_qualifications, temp.apprenticeship, temp.level_4_qualifications_and_above, temp.other_qualifications, \n",
    "            temp.num_aged_16_plus_unemployed, temp.num_aged_16_plus_employed, temp.num_aged_16_plus_self_employed, \n",
    "            temp.deprivation_average_score, temp.deprivation_employment_ratio, temp.qualification_adjusted_employment_rate, \n",
    "            NOW() AS start_date, NULL AS end_date, TRUE AS is_current\n",
    "        FROM (\n",
    "            SELECT temp.*, \n",
    "                   ROW_NUMBER() OVER (PARTITION BY temp.local_authority_code ORDER BY temp.date DESC) AS rn\n",
    "            FROM education_employment_dimension_temp temp\n",
    "        ) temp\n",
    "        WHERE temp.rn = 1;\n",
    "        \"\"\")\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "        INSERT INTO education_employment_dimension (local_authority_code, date, qualification_index_score, \n",
    "            qualification_index_rank, no_qualifications, level_1_and_entry_level_qualifications, level_2_qualifications, \n",
    "            level_3_qualifications, apprenticeship, level_4_qualifications_and_above, other_qualifications, \n",
    "            num_aged_16_plus_unemployed, num_aged_16_plus_employed, num_aged_16_plus_self_employed, \n",
    "            deprivation_average_score, deprivation_employment_ratio, qualification_adjusted_employment_rate, \n",
    "            start_date, end_date, is_current)\n",
    "        SELECT temp.local_authority_code, temp.date, temp.qualification_index_score, temp.qualification_index_rank, \n",
    "            temp.no_qualifications, temp.level_1_and_entry_level_qualifications, temp.level_2_qualifications, \n",
    "            temp.level_3_qualifications, temp.apprenticeship, temp.level_4_qualifications_and_above, temp.other_qualifications, \n",
    "            temp.num_aged_16_plus_unemployed, temp.num_aged_16_plus_employed, temp.num_aged_16_plus_self_employed, \n",
    "            temp.deprivation_average_score, temp.deprivation_employment_ratio, temp.qualification_adjusted_employment_rate, \n",
    "            NOW() AS start_date, NOW() AS end_date, FALSE AS is_current\n",
    "        FROM (\n",
    "            SELECT temp.*, \n",
    "                   ROW_NUMBER() OVER (PARTITION BY temp.local_authority_code ORDER BY temp.date DESC) AS rn\n",
    "            FROM education_employment_dimension_temp temp\n",
    "        ) temp\n",
    "        WHERE temp.rn > 1;\n",
    "        \"\"\")\n",
    "        \n",
    "        drop_temp_table(cursor, 'education_employment_dimension_temp')\n",
    "        connection.commit()\n",
    "        print(\"Initial load for education_employment_dimension completed.\")\n",
    "        info_logger.info(\"Initial load for education_dimension completed\")\n",
    "        \n",
    "def load_demographics_dimension():\n",
    "    \"\"\"Loads data into demographics_dimension table.\"\"\"\n",
    "    with get_db_connection() as connection:\n",
    "        cursor = connection.cursor()\n",
    "        create_temp_table(cursor, 'demographics_dimension_temp',\n",
    "            'local_authority_code VARCHAR(255), date DATE, area_sq_km FLOAT, age_0_20 FLOAT, age_20_40 FLOAT, age_40_60 FLOAT, age_60_plus FLOAT, female_population FLOAT, all_ages FLOAT, male_population FLOAT, age_dependency_ratio FLOAT, est_num_households_with_child FLOAT')\n",
    "        \n",
    "        insert_data(cursor, 'demographics_dimension_temp',\n",
    "                    ['local_authority_code', 'date', 'area_sq_km', 'age_0_20', 'age_20_40', 'age_40_60', 'age_60_plus', 'female_population', 'all_ages', 'male_population', 'age_dependency_ratio', 'est_num_households_with_child'],\n",
    "                    initial_load_df)\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "        INSERT INTO demographics_dimension (local_authority_code, date, area_sq_km, age_0_20, age_20_40, age_40_60, age_60_plus, female_population, all_ages, male_population, age_dependency_ratio, est_num_households_with_child, start_date, end_date, is_current)\n",
    "        SELECT temp.local_authority_code, temp.date, temp.area_sq_km, temp.age_0_20, temp.age_20_40, temp.age_40_60, temp.age_60_plus, temp.female_population, temp.all_ages, temp.male_population, temp.age_dependency_ratio, temp.est_num_households_with_child, NOW() AS start_date, NULL AS end_date, TRUE AS is_current\n",
    "        FROM (\n",
    "            SELECT temp.*, \n",
    "                   ROW_NUMBER() OVER (PARTITION BY temp.local_authority_code ORDER BY temp.date DESC) AS rn\n",
    "            FROM demographics_dimension_temp temp\n",
    "        ) temp\n",
    "        WHERE temp.rn = 1;\n",
    "        \"\"\")\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "        INSERT INTO demographics_dimension (local_authority_code, date, area_sq_km, age_0_20, age_20_40, age_40_60, age_60_plus, female_population, all_ages, male_population, age_dependency_ratio, est_num_households_with_child, start_date, end_date, is_current)\n",
    "        SELECT temp.local_authority_code, temp.date, temp.area_sq_km, temp.age_0_20, temp.age_20_40, temp.age_40_60, temp.age_60_plus, temp.female_population, temp.all_ages, temp.male_population, temp.age_dependency_ratio, temp.est_num_households_with_child, NOW() AS start_date, NOW() AS end_date, FALSE AS is_current\n",
    "        FROM (\n",
    "            SELECT temp.*, \n",
    "                   ROW_NUMBER() OVER (PARTITION BY temp.local_authority_code ORDER BY temp.date DESC) AS rn\n",
    "            FROM demographics_dimension_temp temp\n",
    "        ) temp\n",
    "        WHERE temp.rn > 1;\n",
    "        \"\"\")\n",
    "        \n",
    "        drop_temp_table(cursor, 'demographics_dimension_temp')\n",
    "        connection.commit()\n",
    "        print(\"Initial load for demographics_dimension completed.\")\n",
    "        info_logger.info(\"Initial load for demographics_dimension completed\")\n",
    "        \n",
    "def load_sales_transaction_fact():\n",
    "    \"\"\"Loads data into sales_transactions_fact table.\"\"\"\n",
    "    with get_db_connection() as connection:\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Create the temporary table\n",
    "        create_temp_table(cursor, 'sales_transactions_fact_temp',\n",
    "            'local_authority_code VARCHAR(255), date DATE, price NUMERIC, average_price FLOAT, predicted_price_unscaled FLOAT, index FLOAT, average_price_pct_change FLOAT, annual_change_percent FLOAT, new_price FLOAT, old_price FLOAT, sales_volume FLOAT, sales_volume_log FLOAT, old_sales_volume FLOAT, detached_flat_ratio FLOAT, detached_terraced_ratio FLOAT, semi_detached_price_pct_change FLOAT, detached_semi_detached_ratio FLOAT, detached_price_log FLOAT, semi_detached_price_log FLOAT, flat_price_log FLOAT, terraced_price_pct_change FLOAT, terraced_price_log FLOAT, gdhi FLOAT, deprivation_adjusted_gdhi FLOAT, gdhi_per_capita FLOAT, foo_price FLOAT, cash_price FLOAT, mortgage_price FLOAT, housing_demand_indicator FLOAT, deprivation_reduction_potential FLOAT, flat_price_pct_change FLOAT, detached_price_pct_change FLOAT, average_price_log FLOAT, ftb_price FLOAT')\n",
    "\n",
    "        # Insert data into the temporary table\n",
    "        insert_data(cursor, 'sales_transactions_fact_temp',\n",
    "                    ['local_authority_code', 'date', 'price', 'average_price', 'predicted_price_unscaled', 'index', 'average_price_pct_change', 'annual_change_percent', 'new_price', 'old_price', 'sales_volume', 'sales_volume_log', 'old_sales_volume', 'detached_flat_ratio', 'detached_terraced_ratio', 'semi_detached_price_pct_change', 'detached_semi_detached_ratio', 'detached_price_log', 'semi_detached_price_log', 'flat_price_log', 'terraced_price_pct_change', 'terraced_price_log', 'gdhi', 'deprivation_adjusted_gdhi', 'gdhi_per_capita', 'foo_price', 'cash_price', 'mortgage_price', 'housing_demand_indicator', 'deprivation_reduction_potential', 'flat_price_pct_change', 'detached_price_pct_change', 'average_price_log', 'ftb_price'],\n",
    "                    initial_load_df)\n",
    "\n",
    "        # Insert the latest records into the fact table\n",
    "        cursor.execute(\"\"\"\n",
    "        INSERT INTO sales_transactions_fact (\n",
    "            local_authority_code, date, district_id, region_id, property_type_id, vehicle_id, \n",
    "            rental_id, demographics_id, education_employment_id, date_key, price, average_price, \n",
    "            predicted_price_unscaled, index, average_price_pct_change, annual_change_percent, \n",
    "            new_price, old_price, sales_volume, sales_volume_log, \n",
    "            old_sales_volume, detached_flat_ratio, detached_terraced_ratio, semi_detached_price_pct_change, \n",
    "            detached_semi_detached_ratio, detached_price_log, semi_detached_price_log, \n",
    "            flat_price_log, terraced_price_pct_change, terraced_price_log, gdhi, \n",
    "            deprivation_adjusted_gdhi, gdhi_per_capita, foo_price, cash_price, mortgage_price, \n",
    "            housing_demand_indicator, deprivation_reduction_potential, flat_price_pct_change, detached_price_pct_change, average_price_log, ftb_price, start_date, is_current\n",
    "        )\n",
    "        SELECT \n",
    "            temp.local_authority_code, temp.date, \n",
    "            dd.district_id, rd.region_id, ptd.property_type_id, vd.vehicle_id, \n",
    "            rentald.rental_id, ddemo.demographics_id, eed.education_employment_id, d.date_key,\n",
    "            temp.price, temp.average_price, temp.predicted_price_unscaled, temp.index, \n",
    "            temp.average_price_pct_change, temp.annual_change_percent,\n",
    "            temp.new_price, temp.old_price, temp.sales_volume, temp.sales_volume_log, \n",
    "            temp.old_sales_volume, temp.detached_flat_ratio, temp.detached_terraced_ratio, \n",
    "            temp.semi_detached_price_pct_change, temp.detached_semi_detached_ratio, \n",
    "            temp.detached_price_log, temp.semi_detached_price_log, temp.flat_price_log, \n",
    "            temp.terraced_price_pct_change, temp.terraced_price_log, temp.gdhi, \n",
    "            temp.deprivation_adjusted_gdhi, temp.gdhi_per_capita, temp.foo_price, temp.cash_price, \n",
    "            temp.mortgage_price, temp.housing_demand_indicator, temp.deprivation_reduction_potential,\n",
    "            temp.flat_price_pct_change, temp.detached_price_pct_change, temp.average_price_log, temp.ftb_price,\n",
    "            NOW() AS start_date, TRUE AS is_current\n",
    "        FROM \n",
    "            sales_transactions_fact_temp temp\n",
    "        JOIN \n",
    "            district_dimension dd ON dd.local_authority_code = temp.local_authority_code AND dd.date = temp.date\n",
    "        JOIN \n",
    "            region_dimension rd ON rd.local_authority_code = temp.local_authority_code\n",
    "        JOIN \n",
    "            property_type_dimension ptd ON ptd.local_authority_code = temp.local_authority_code AND ptd.date = temp.date\n",
    "        JOIN \n",
    "            vehicle_dimension vd ON vd.local_authority_code = temp.local_authority_code\n",
    "        JOIN \n",
    "            rental_dimension rentald ON rentald.local_authority_code = temp.local_authority_code AND rentald.date = temp.date\n",
    "        JOIN \n",
    "            demographics_dimension ddemo ON ddemo.local_authority_code = temp.local_authority_code AND ddemo.date = temp.date\n",
    "        JOIN \n",
    "            education_employment_dimension eed ON eed.local_authority_code = temp.local_authority_code AND eed.date = temp.date\n",
    "        JOIN \n",
    "            date_dimension d ON d.date = temp.date;\n",
    "        \"\"\")\n",
    "\n",
    "        # Inserting the historical records with end_date set\n",
    "        cursor.execute(\"\"\"\n",
    "        UPDATE sales_transactions_fact\n",
    "        SET end_date = NOW(), is_current = FALSE\n",
    "        WHERE local_authority_code IN (\n",
    "            SELECT local_authority_code \n",
    "            FROM sales_transactions_fact_temp\n",
    "        ) \n",
    "        AND is_current = TRUE\n",
    "        AND date < (SELECT MAX(date) FROM sales_transactions_fact_temp WHERE local_authority_code = sales_transactions_fact.local_authority_code);\n",
    "        \"\"\")\n",
    "\n",
    "        # Droping the temporary table\n",
    "        drop_temp_table(cursor, 'sales_transactions_fact_temp')\n",
    "        \n",
    "        connection.commit()\n",
    "        print(\"Initial load for sales_transactions_fact completed.\")\n",
    "        info_logger.info(\"Initial load for sales_transactions_fact completed\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40117e4f-18b1-40bd-b244-d0e34a116227",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:39:00.101953Z",
     "iopub.status.busy": "2024-09-12T12:39:00.101953Z",
     "iopub.status.idle": "2024-09-12T12:39:04.967509Z",
     "shell.execute_reply": "2024-09-12T12:39:04.967509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial load for region_dimension completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded region dimension.\n",
      "Initial load for date_dimension completed.\n",
      "Loaded date dimension.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial load for rental_dimension completed.\n",
      "Loaded rental dimension.\n",
      "Initial load for vehicle_dimension completed.\n",
      "Loaded vehicle dimension.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial load for district_dimension completed.\n",
      "Loaded district dimension.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial load for property_type_dimension completed.\n",
      "Loaded property type dimension.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial load for education_employment_dimension completed.\n",
      "Loaded education and employment dimension.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial load for demographics_dimension completed.\n",
      "Loaded demographics dimension.\n",
      "All dimensions have been loaded successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial load for sales_transactions_fact completed.\n",
      "Loaded sales transactions fact.\n",
      "All facts have been loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to load data into all dimension and fact tables. \n",
    "    Stops execution if an error occurs during any data loading step.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Loading data into the region_dimension table\n",
    "        load_region_dimension()\n",
    "        print(\"Loaded region dimension.\")\n",
    "\n",
    "        # Loading data into the date_dimension table\n",
    "        load_date_dimension()\n",
    "        print(\"Loaded date dimension.\")\n",
    "\n",
    "        # Loading data into the rental_dimension table\n",
    "        load_rental_dimension()\n",
    "        print(\"Loaded rental dimension.\")\n",
    "\n",
    "        # Loading data into the vehicle_dimension table\n",
    "        load_vehicle_dimension()\n",
    "        print(\"Loaded vehicle dimension.\")\n",
    "\n",
    "        # Loading data into the district_dimension table\n",
    "        load_district_dimension()\n",
    "        print(\"Loaded district dimension.\")\n",
    "\n",
    "        # Loading data into the property_type_dimension table\n",
    "        load_property_type_dimension()\n",
    "        print(\"Loaded property type dimension.\")\n",
    "\n",
    "        # Loading data into the education_employment_dimension table\n",
    "        load_education_employment_dimension()\n",
    "        print(\"Loaded education and employment dimension.\")\n",
    "\n",
    "        # Load data into the demographics_dimension table\n",
    "        load_demographics_dimension()\n",
    "        print(\"Loaded demographics dimension.\")\n",
    "\n",
    "        # Confirming successful completion\n",
    "        print(\"All dimensions have been loaded successfully.\")\n",
    "        \n",
    "        # Loading data into the sales_transactions_fact table\n",
    "        load_sales_transaction_fact()\n",
    "        print(\"Loaded sales transactions fact.\")\n",
    "\n",
    "        # Confirming successful completion\n",
    "        print(\"All facts have been loaded successfully.\")\n",
    "               \n",
    "    except Exception as e:\n",
    "        # If an error occurs, printing an error message and stoping execution\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Entry point for script execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Making a copy of the data to be used in the loading functions\n",
    "    initial_load_df = data_load_df.copy()\n",
    "\n",
    "    # Running the main function to start the data loading process\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d92decb-df11-46a2-9e94-20eace1aa14d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:39:04.970315Z",
     "iopub.status.busy": "2024-09-12T12:39:04.968890Z",
     "iopub.status.idle": "2024-09-12T12:39:05.019085Z",
     "shell.execute_reply": "2024-09-12T12:39:05.017055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata for all tables updated successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Connect to PostgreSQL database\n",
    "connection = psycopg2.connect(\n",
    "    dbname='UK Real Estate DB',\n",
    "    user='postgres',\n",
    "    password='123!@*qweQWE',\n",
    "    host='localhost',\n",
    "    port='5432'\n",
    ")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Listing target tables and their SCD types\n",
    "tables_metadata = [\n",
    "    {\"table_name\": \"region_dimension\", \"scd_type\": 1},\n",
    "    {\"table_name\": \"date_dimension\", \"scd_type\": 0},\n",
    "    {\"table_name\": \"sales_transactions_fact\", \"scd_type\": 2},\n",
    "    {\"table_name\": \"vehicle_dimension\", \"scd_type\": 1},\n",
    "    {\"table_name\": \"rental_dimension\", \"scd_type\": 2},\n",
    "    {\"table_name\": \"demographics_dimension\", \"scd_type\": 2},\n",
    "    {\"table_name\": \"education_employment_dimension\", \"scd_type\": 2},\n",
    "    {\"table_name\": \"property_type_dimension\", \"scd_type\": 2},\n",
    "    {\"table_name\": \"district_dimension\", \"scd_type\": 2}\n",
    "]\n",
    "\n",
    "# Setting the extraction timestamp as the current time\n",
    "last_extracted_date = datetime.now()\n",
    "\n",
    "# Inserting metadata records\n",
    "for table in tables_metadata:\n",
    "    insert_metadata_query = \"\"\"\n",
    "    INSERT INTO metadata (table_name, last_extracted_date, scd_type, last_modified_date, created_date)\n",
    "    VALUES (%s, %s, %s, %s, %s);\n",
    "    \"\"\"\n",
    "    cursor.execute(insert_metadata_query, (\n",
    "        table['table_name'],\n",
    "        last_extracted_date,\n",
    "        table['scd_type'],\n",
    "        last_extracted_date,\n",
    "        last_extracted_date\n",
    "    ))\n",
    "\n",
    "# Commiting the transaction\n",
    "connection.commit()\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "print(\"Metadata for all tables updated successfully.\")\n",
    "info_logger.info(\"Metadata for all tables updated successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd6729f-c52a-4c2d-ab8f-8ed7275c4bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
