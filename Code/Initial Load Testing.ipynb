{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "301cb34e-ce1c-4535-9ff3-5610aefa2826",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:39:09.671901Z",
     "iopub.status.busy": "2024-09-12T12:39:09.671901Z",
     "iopub.status.idle": "2024-09-12T12:39:09.695210Z",
     "shell.execute_reply": "2024-09-12T12:39:09.694519Z"
    }
   },
   "outputs": [],
   "source": [
    "import psycopg2  # Importing PostgreSQL database adapter for Python\n",
    "from psycopg2 import sql  # Importing SQL module for safely constructing SQL queries\n",
    "import os  # Importing OS module for interacting with the operating system\n",
    "import logging  # Importing logging module for event tracking and debugging\n",
    "import warnings  # Warnings module to control warning messages\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1890392-cd5d-4db2-a513-adbb6017e674",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:39:09.697695Z",
     "iopub.status.busy": "2024-09-12T12:39:09.697695Z",
     "iopub.status.idle": "2024-09-12T12:39:09.701560Z",
     "shell.execute_reply": "2024-09-12T12:39:09.701560Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "notebook_name = 'Initial Load Testing' \n",
    "\n",
    "# Paths for the log directories\n",
    "info_log_path = f'../Logs/info/{notebook_name}_info.log'\n",
    "\n",
    "# Creating directories if they don't exist\n",
    "os.makedirs(os.path.dirname(info_log_path), exist_ok=True)\n",
    "\n",
    "# Clearing any previous handlers if re-running this setup\n",
    "logger = logging.getLogger()\n",
    "while logger.handlers:\n",
    "    logger.handlers.pop()\n",
    "\n",
    "# Configuring logging\n",
    "info_logger = logging.getLogger('info_logger')\n",
    "\n",
    "info_handler = logging.FileHandler(info_log_path, mode='a')  # Append mode\n",
    "\n",
    "info_handler.setLevel(logging.INFO)\n",
    "\n",
    "# Consistent formatter for both handlers\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "info_handler.setFormatter(formatter)\n",
    "\n",
    "# Adding handlers to the loggers\n",
    "info_logger.addHandler(info_handler)\n",
    "\n",
    "info_logger.setLevel(logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d922c65c-a4e8-4d4e-938f-0badfd9fa09f",
   "metadata": {},
   "source": [
    "### Initial load for all dimension and fact tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93e40fec-4f12-40ba-a744-d262d9a01826",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:39:09.704580Z",
     "iopub.status.busy": "2024-09-12T12:39:09.704580Z",
     "iopub.status.idle": "2024-09-12T12:39:09.862103Z",
     "shell.execute_reply": "2024-09-12T12:39:09.862103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running record_completeness : region_dimension...\n",
      "('Total Records in Dimension', 292)\n",
      "('Records from Source Table', 292)\n",
      "Completed record_completeness : region_dimension\n",
      "Running null_checks : region_dimension...\n",
      "(0, 0, 0, 0)\n",
      "Completed null_checks : region_dimension\n",
      "Running duplicate_records_check : region_dimension...\n",
      "Completed duplicate_records_check : region_dimension\n",
      "Running accuracy_check : region_dimension...\n",
      "('Records in source not in target', 0)\n",
      "('Records in target not in source', 0)\n",
      "Completed accuracy_check : region_dimension\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Database credentials\n",
    "DB_CONFIG = {\n",
    "    'dbname': 'UK Real Estate DB',\n",
    "    'user': 'postgres',\n",
    "    'password': '123!@*qweQWE',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "# Queries to execute\n",
    "queries = {\n",
    "    \"record_completeness : region_dimension\": \"\"\"\n",
    "        -- Verify the number of records loaded into the dimension\n",
    "        SELECT \n",
    "            'Total Records in Dimension' AS description,\n",
    "            COUNT(*) AS count\n",
    "        FROM region_dimension\n",
    "        UNION ALL\n",
    "        SELECT \n",
    "            'Records from Source Table' AS description,\n",
    "            COUNT(DISTINCT local_authority_code) AS count\n",
    "        FROM initial_load_etl_source_data;\n",
    "    \"\"\",\n",
    "    \"null_checks : region_dimension\": \"\"\"\n",
    "        -- Check for NULL values in essential fields\n",
    "        SELECT\n",
    "          SUM(CASE WHEN region_code IS NULL THEN 1 ELSE 0 END) AS null_region_code,\n",
    "          SUM(CASE WHEN region_name IS NULL THEN 1 ELSE 0 END) AS null_region_name,\n",
    "          SUM(CASE WHEN local_authority_code IS NULL THEN 1 ELSE 0 END) AS null_local_authority_code,\n",
    "          SUM(CASE WHEN local_authority_name IS NULL THEN 1 ELSE 0 END) AS null_local_authority_name\n",
    "        FROM region_dimension;\n",
    "    \"\"\",\n",
    "    \"duplicate_records_check : region_dimension\": \"\"\"\n",
    "        -- Check for duplicate records in the dimension\n",
    "        SELECT \n",
    "            local_authority_code, \n",
    "            COUNT(*) AS duplicate_count\n",
    "        FROM \n",
    "            region_dimension\n",
    "        GROUP BY \n",
    "            local_authority_code\n",
    "        HAVING \n",
    "            COUNT(*) > 1;\n",
    "    \"\"\",\n",
    "    \"accuracy_check : region_dimension\": \"\"\"\n",
    "        -- Check records from source not in target and vice versa\n",
    "        SELECT 'Records in source not in target' AS description, COUNT(*) AS count\n",
    "        FROM (\n",
    "            SELECT local_authority_code, region_code, region_name, local_authority_name\n",
    "            FROM initial_load_etl_source_data\n",
    "            EXCEPT\n",
    "            SELECT local_authority_code, region_code, region_name, local_authority_name\n",
    "            FROM region_dimension\n",
    "        ) AS missing_records\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        SELECT 'Records in target not in source' AS description, COUNT(*) AS count\n",
    "        FROM (\n",
    "            SELECT local_authority_code, region_code, region_name, local_authority_name\n",
    "            FROM region_dimension\n",
    "            EXCEPT\n",
    "            SELECT local_authority_code, region_code, region_name, local_authority_name\n",
    "            FROM initial_load_etl_source_data\n",
    "        ) AS extra_records;\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "def execute_query(query, output_file):\n",
    "    \"\"\" Executes SQL query and write results to a file, also print the results.\"\"\"\n",
    "    \n",
    "    # Establishing a connection to the database using the provided configuration\n",
    "    with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "        \n",
    "        # Creating a cursor object for executing the query\n",
    "        with conn.cursor() as cur:\n",
    "            \n",
    "            # Executing the provided SQL query\n",
    "            cur.execute(query)\n",
    "            # Fetching all query results\n",
    "            results = cur.fetchall()\n",
    "            \n",
    "            # Iterating through the results, writing each row to the output file and printing\n",
    "            for row in results:\n",
    "                line = str(row) + '\\n'\n",
    "                output_file.write(line)\n",
    "                print(line.strip())  # Print each row\n",
    "\n",
    "def main():\n",
    "    # Defining the path for saving query results\n",
    "    results_path = '../Results/region_dimension_query_results.txt'\n",
    "    \n",
    "    # Opening the output file in write mode\n",
    "    with open(results_path, 'w') as output_file:\n",
    "\n",
    "        # Iterating through each query and running it\n",
    "        for description, query in queries.items():\n",
    "            \n",
    "            # Writing and printing the message for the running query\n",
    "            message = f\"Running {description}...\\n\"\n",
    "            output_file.write(message)\n",
    "            print(message.strip())  # Print the running message\n",
    "\n",
    "            # Executing the SQL query\n",
    "            execute_query(query, output_file)\n",
    "\n",
    "            # Writing and printing the completion message after the query execution\n",
    "            completed_message = f\"Completed {description}\\n\\n\"\n",
    "            output_file.write(completed_message)\n",
    "            print(completed_message.strip())  # Print the completed message\n",
    "\n",
    "# Calling the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "info_logger.info(\"Testing completed for Region dimension\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17872491-e1d3-4344-a636-3efd5ecb22cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:39:09.865337Z",
     "iopub.status.busy": "2024-09-12T12:39:09.865337Z",
     "iopub.status.idle": "2024-09-12T12:39:10.014787Z",
     "shell.execute_reply": "2024-09-12T12:39:10.013782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running record_completeness : date_dimension...\n",
      "('Total Records in Dimension', 12)\n",
      "('Records from Source Table', 12)\n",
      "Completed record_completeness : date_dimension\n",
      "Running null_checks : date_dimension...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 0, 0, 0)\n",
      "Completed null_checks : date_dimension\n",
      "Running duplicate_records_check : date_dimension...\n",
      "Completed duplicate_records_check : date_dimension\n",
      "Running accuracy_check : date_dimension...\n",
      "('Records in source not in target', 0)\n",
      "('Records in target not in source', 0)\n",
      "Completed accuracy_check : date_dimension\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Database credentials\n",
    "DB_CONFIG = {\n",
    "    'dbname': 'UK Real Estate DB',\n",
    "    'user': 'postgres',\n",
    "    'password': '123!@*qweQWE',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "# Queries to execute\n",
    "queries = {\n",
    "    \"record_completeness : date_dimension\": \"\"\"\n",
    "        -- Verify the number of records loaded into the dimension\n",
    "        SELECT \n",
    "            'Total Records in Dimension' AS description,\n",
    "            COUNT(*) AS count\n",
    "        FROM date_dimension\n",
    "        UNION ALL\n",
    "        SELECT \n",
    "            'Records from Source Table' AS description,\n",
    "            COUNT(DISTINCT date) AS count\n",
    "        FROM initial_load_etl_source_data;\n",
    "    \"\"\",\n",
    "    \"null_checks : date_dimension\": \"\"\"\n",
    "        -- Check for NULL values in essential fields\n",
    "        SELECT\n",
    "          SUM(CASE WHEN date IS NULL THEN 1 ELSE 0 END) AS null_date,\n",
    "          SUM(CASE WHEN month IS NULL THEN 1 ELSE 0 END) AS null_month,\n",
    "          SUM(CASE WHEN quarter IS NULL THEN 1 ELSE 0 END) AS null_quarter,\n",
    "          SUM(CASE WHEN year IS NULL THEN 1 ELSE 0 END) AS null_year,\n",
    "          SUM(CASE WHEN transfer_month_year IS NULL THEN 1 ELSE 0 END) AS null_transfer_month_year\n",
    "        FROM date_dimension;\n",
    "    \"\"\",\n",
    "    \"duplicate_records_check : date_dimension\": \"\"\"\n",
    "        -- Check for duplicate records in the dimension\n",
    "        SELECT \n",
    "            date, \n",
    "            COUNT(*) AS duplicate_count\n",
    "        FROM \n",
    "            date_dimension\n",
    "        GROUP BY \n",
    "            date\n",
    "        HAVING \n",
    "            COUNT(*) > 1;\n",
    "    \"\"\",\n",
    "    \"accuracy_check : date_dimension\": \"\"\"\n",
    "        -- Check records from source not in target and vice versa\n",
    "        SELECT 'Records in source not in target' AS description, COUNT(*) AS count\n",
    "        FROM (\n",
    "            SELECT date, month, quarter, year, transfer_month_year\n",
    "            FROM initial_load_etl_source_data\n",
    "            EXCEPT\n",
    "            SELECT date, month, quarter, year, transfer_month_year\n",
    "            FROM date_dimension\n",
    "        ) AS missing_records\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        SELECT 'Records in target not in source' AS description, COUNT(*) AS count\n",
    "        FROM (\n",
    "            SELECT date, month, quarter, year, transfer_month_year\n",
    "            FROM date_dimension\n",
    "            EXCEPT\n",
    "            SELECT date, month, quarter, year, transfer_month_year\n",
    "            FROM initial_load_etl_source_data\n",
    "        ) AS extra_records;\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "\n",
    "def execute_query(query, output_file):\n",
    "    \"\"\" Executes SQL query and write results to a file, also print the results.\"\"\"\n",
    "    \n",
    "    # Establishing a connection to the database using the provided configuration\n",
    "    with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "        \n",
    "        # Creating a cursor object for executing the query\n",
    "        with conn.cursor() as cur:\n",
    "            \n",
    "            # Executing the provided SQL query\n",
    "            cur.execute(query)\n",
    "            # Fetching all query results\n",
    "            results = cur.fetchall()\n",
    "            \n",
    "            # Iterating through the results, writing each row to the output file and printing\n",
    "            for row in results:\n",
    "                line = str(row) + '\\n'\n",
    "                output_file.write(line)\n",
    "                print(line.strip())  # Print each row\n",
    "\n",
    "def main():\n",
    "    # Defining the path for saving query results\n",
    "    results_path = '../Results/date_dimension_query_results.txt' \n",
    "    \n",
    "    # Opening the output file in write mode\n",
    "    with open(results_path, 'w') as output_file:\n",
    "\n",
    "        # Iterating through each query and running it\n",
    "        for description, query in queries.items():\n",
    "            \n",
    "            # Writing and printing the message for the running query\n",
    "            message = f\"Running {description}...\\n\"\n",
    "            output_file.write(message)\n",
    "            print(message.strip())  # Print the running message\n",
    "\n",
    "            # Executing the SQL query\n",
    "            execute_query(query, output_file)\n",
    "\n",
    "            # Writing and printing the completion message after the query execution\n",
    "            completed_message = f\"Completed {description}\\n\\n\"\n",
    "            output_file.write(completed_message)\n",
    "            print(completed_message.strip())  # Print the completed message\n",
    "\n",
    "# Calling the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "info_logger.info(\"Testing completed for Date dimension\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "552eda33-4966-476b-a11f-4b4e11352175",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:39:10.018235Z",
     "iopub.status.busy": "2024-09-12T12:39:10.018235Z",
     "iopub.status.idle": "2024-09-12T12:39:10.187224Z",
     "shell.execute_reply": "2024-09-12T12:39:10.187224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running record_completeness : vehicle_dimension...\n",
      "('Source Unique Local Authority Codes', 292)\n",
      "('Dimension Unique Records', 292)\n",
      "Completed record_completeness : vehicle_dimension\n",
      "Running null_checks : vehicle_dimension...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "Completed null_checks : vehicle_dimension\n",
      "Running duplicate_records_check : vehicle_dimension...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed duplicate_records_check : vehicle_dimension\n",
      "Running accuracy_check : vehicle_dimension...\n",
      "('Records in source not in target', 0)\n",
      "('Records in target not in source', 0)\n",
      "Completed accuracy_check : vehicle_dimension\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Database credentials\n",
    "DB_CONFIG = {\n",
    "    'dbname': 'UK Real Estate DB',\n",
    "    'user': 'postgres',\n",
    "    'password': '123!@*qweQWE',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "# Queries to execute\n",
    "queries = {\n",
    "    \"record_completeness : vehicle_dimension\": \"\"\"\n",
    "        -- Verify the number of records loaded into the dimension\n",
    "        SELECT \n",
    "            'Source Unique Local Authority Codes' AS description,\n",
    "            COUNT(DISTINCT local_authority_code) AS count\n",
    "        FROM initial_load_etl_source_data\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        SELECT \n",
    "            'Dimension Unique Records' AS description,\n",
    "            COUNT(DISTINCT local_authority_code) AS count\n",
    "        FROM vehicle_dimension;\n",
    "    \"\"\",\n",
    "    \"null_checks : vehicle_dimension\": \"\"\"\n",
    "        -- Check for NULL values in essential fields\n",
    "        SELECT\n",
    "          SUM(CASE WHEN local_authority_code IS NULL THEN 1 ELSE 0 END) AS null_in_local_authority_code,\n",
    "          SUM(CASE WHEN region_id IS NULL THEN 1 ELSE 0 END) AS null_in_region_id,\n",
    "          SUM(CASE WHEN buses_total IS NULL THEN 1 ELSE 0 END) AS null_in_buses_total,\n",
    "          SUM(CASE WHEN petrol_cars_total IS NULL THEN 1 ELSE 0 END) AS null_in_petrol_cars_total,\n",
    "          SUM(CASE WHEN hgv_total IS NULL THEN 1 ELSE 0 END) AS null_in_hgv_total,\n",
    "          SUM(CASE WHEN petrol_lgv_total IS NULL THEN 1 ELSE 0 END) AS null_in_petrol_lgv_total,\n",
    "          SUM(CASE WHEN lpg_lgv_total IS NULL THEN 1 ELSE 0 END) AS null_in_lpg_lgv_total,\n",
    "          SUM(CASE WHEN hgv_motorways IS NULL THEN 1 ELSE 0 END) AS null_in_hgv_motorways,\n",
    "          SUM(CASE WHEN personal_transport IS NULL THEN 1 ELSE 0 END) AS null_in_personal_transport\n",
    "        FROM vehicle_dimension;\n",
    "\n",
    "    \"\"\",\n",
    "    \"duplicate_records_check : vehicle_dimension\": \"\"\"\n",
    "        -- Check for duplicate records in the dimension\n",
    "        SELECT \n",
    "            local_authority_code, \n",
    "            COUNT(*) AS duplicate_count\n",
    "        FROM \n",
    "            vehicle_dimension\n",
    "        GROUP BY \n",
    "            local_authority_code\n",
    "        HAVING \n",
    "            COUNT(*) > 1;\n",
    "    \"\"\",\n",
    "       \"accuracy_check : vehicle_dimension\": \"\"\"\n",
    "        -- Check records from source not in target and vice versa\n",
    "        SELECT 'Records in source not in target' AS description, COUNT(*) AS count\n",
    "        FROM (\n",
    "            SELECT local_authority_code, buses_total, petrol_cars_total, hgv_total, petrol_lgv_total, \n",
    "                   lpg_lgv_total, hgv_motorways, personal_transport\n",
    "            FROM initial_load_etl_source_data\n",
    "            EXCEPT\n",
    "            SELECT local_authority_code, buses_total, petrol_cars_total, hgv_total, petrol_lgv_total, \n",
    "                   lpg_lgv_total, hgv_motorways, personal_transport\n",
    "            FROM vehicle_dimension\n",
    "        ) AS missing_records\n",
    "    \n",
    "        UNION ALL\n",
    "    \n",
    "        SELECT 'Records in target not in source' AS description, COUNT(*) AS count\n",
    "        FROM (\n",
    "            SELECT local_authority_code, buses_total, petrol_cars_total, hgv_total, petrol_lgv_total, \n",
    "                   lpg_lgv_total, hgv_motorways, personal_transport\n",
    "            FROM vehicle_dimension\n",
    "            EXCEPT\n",
    "            SELECT local_authority_code, buses_total, petrol_cars_total, hgv_total, petrol_lgv_total, \n",
    "                   lpg_lgv_total, hgv_motorways, personal_transport\n",
    "            FROM initial_load_etl_source_data\n",
    "        ) AS extra_records;\n",
    "    \"\"\"\n",
    "\n",
    "}\n",
    "\n",
    "def execute_query(query, output_file):\n",
    "    \"\"\" Executes SQL query and write results to a file, also print the results.\"\"\"\n",
    "    \n",
    "    # Establishing a connection to the database using the provided configuration\n",
    "    with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "        \n",
    "        # Creating a cursor object for executing the query\n",
    "        with conn.cursor() as cur:\n",
    "            \n",
    "            # Executing the provided SQL query\n",
    "            cur.execute(query)\n",
    "            # Fetching all query results\n",
    "            results = cur.fetchall()\n",
    "            \n",
    "            # Iterating through the results, writing each row to the output file and printing\n",
    "            for row in results:\n",
    "                line = str(row) + '\\n'\n",
    "                output_file.write(line)\n",
    "                print(line.strip())  # Print each row\n",
    "\n",
    "def main():\n",
    "    # Defining the path for saving query results\n",
    "    results_path = '../Results/vehicle_dimension_query_results.txt' \n",
    "    \n",
    "    # Opening the output file in write mode\n",
    "    with open(results_path, 'w') as output_file:\n",
    "\n",
    "        # Iterating through each query and running it\n",
    "        for description, query in queries.items():\n",
    "            \n",
    "            # Writing and printing the message for the running query\n",
    "            message = f\"Running {description}...\\n\"\n",
    "            output_file.write(message)\n",
    "            print(message.strip())  # Print the running message\n",
    "\n",
    "            # Executing the SQL query\n",
    "            execute_query(query, output_file)\n",
    "\n",
    "            # Writing and printing the completion message after the query execution\n",
    "            completed_message = f\"Completed {description}\\n\\n\"\n",
    "            output_file.write(completed_message)\n",
    "            print(completed_message.strip())  # Print the completed message\n",
    "\n",
    "# Calling the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "info_logger.info(\"Testing completed for Vechile dimension\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e40ae22-3c0f-4642-a941-5ce08b160313",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:39:10.192345Z",
     "iopub.status.busy": "2024-09-12T12:39:10.192345Z",
     "iopub.status.idle": "2024-09-12T12:39:10.450017Z",
     "shell.execute_reply": "2024-09-12T12:39:10.449012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running record_completeness : district_dimension...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total Records in Dimension', 3504)\n",
      "('Records from Source Table', 3504)\n",
      "Completed record_completeness : district_dimension\n",
      "Running null_checks : district_dimension...\n",
      "(0, 0, 0, 0, 0)\n",
      "Completed null_checks : district_dimension\n",
      "Running duplicate_records_check : district_dimension...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed duplicate_records_check : district_dimension\n",
      "Running accuracy_check : district_dimension...\n",
      "('Records in source not in target', 0)\n",
      "('Records in target not in source', 0)\n",
      "Completed accuracy_check : district_dimension\n",
      "Running inactive_records_check : district_dimension...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed inactive_records_check : district_dimension\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Database credentials\n",
    "DB_CONFIG = {\n",
    "    'dbname': 'UK Real Estate DB',\n",
    "    'user': 'postgres',\n",
    "    'password': '123!@*qweQWE',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "# Queries to execute\n",
    "queries = {\n",
    "    \"record_completeness : district_dimension\": \"\"\"\n",
    "        -- Verify the number of records loaded into the dimension\n",
    "        SELECT \n",
    "            'Total Records in Dimension' AS description,\n",
    "            COUNT(*) AS count\n",
    "        FROM district_dimension\n",
    "        UNION ALL\n",
    "        SELECT \n",
    "            'Records from Source Table' AS description,\n",
    "\t\t\tCOUNT(DISTINCT (local_authority_code, date)) AS count\n",
    "        FROM initial_load_etl_source_data\n",
    "    \"\"\",\n",
    "    \"null_checks : district_dimension\": \"\"\"\n",
    "        -- Check for NULL values in essential fields\n",
    "        SELECT\n",
    "          SUM(CASE WHEN local_authority_code IS NULL THEN 1 ELSE 0 END) AS null_local_authority_code,\n",
    "          SUM(CASE WHEN date IS NULL THEN 1 ELSE 0 END) AS null_date,\n",
    "          SUM(CASE WHEN district IS NULL THEN 1 ELSE 0 END) AS null_district,\n",
    "          SUM(CASE WHEN town_city IS NULL THEN 1 ELSE 0 END) AS null_town_city,\n",
    "          SUM(CASE WHEN county IS NULL THEN 1 ELSE 0 END) AS null_county\n",
    "        FROM district_dimension;\n",
    "    \"\"\",\n",
    "    \"duplicate_records_check : district_dimension\": \"\"\"\n",
    "        -- Check for duplicate records in the dimension\n",
    "       SELECT \n",
    "            local_authority_code, \n",
    "            date,\n",
    "            COUNT(*) AS duplicate_count\n",
    "        FROM \n",
    "            district_dimension\n",
    "        GROUP BY \n",
    "            local_authority_code, \n",
    "            date\n",
    "        HAVING \n",
    "            COUNT(*) > 1;\n",
    "    \"\"\",\n",
    "    \"accuracy_check : district_dimension\": \"\"\"\n",
    "        -- Check records from source not in target\n",
    "        SELECT 'Records in source not in target' AS description, COUNT(*) AS count\n",
    "        FROM (\n",
    "            SELECT local_authority_code, date, district, town_city, county\n",
    "            FROM initial_load_etl_source_data\n",
    "            EXCEPT\n",
    "            SELECT local_authority_code, date, district, town_city, county\n",
    "            FROM district_dimension\n",
    "        ) AS missing_records\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        -- Check records in target not in source\n",
    "        SELECT 'Records in target not in source' AS description, COUNT(*) AS count\n",
    "        FROM (\n",
    "            SELECT local_authority_code, date, district, town_city, county\n",
    "            FROM district_dimension\n",
    "            EXCEPT\n",
    "            SELECT local_authority_code, date, district, town_city, county\n",
    "            FROM initial_load_etl_source_data\n",
    "        ) AS extra_records;\n",
    "    \"\"\",\n",
    "    \"inactive_records_check : district_dimension\": \"\"\"\n",
    "        -- Check that all older records are inactive\n",
    "        SELECT \n",
    "            local_authority_code,\n",
    "            date,\n",
    "            is_current\n",
    "        FROM district_dimension\n",
    "        WHERE (local_authority_code, date) NOT IN (\n",
    "            SELECT \n",
    "                local_authority_code,\n",
    "                MAX(date)\n",
    "            FROM initial_load_etl_source_data\n",
    "            GROUP BY local_authority_code\n",
    "        ) AND is_current = TRUE;\n",
    "    \"\"\"\n",
    "    \n",
    "}\n",
    "\n",
    "def execute_query(query, output_file):\n",
    "    \"\"\" Executes SQL query and write results to a file, also print the results.\"\"\"\n",
    "    \n",
    "    # Establishing a connection to the database using the provided configuration\n",
    "    with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "        \n",
    "        # Creating a cursor object for executing the query\n",
    "        with conn.cursor() as cur:\n",
    "            \n",
    "            # Executing the provided SQL query\n",
    "            cur.execute(query)\n",
    "            # Fetching all query results\n",
    "            results = cur.fetchall()\n",
    "            \n",
    "            # Iterating through the results, writing each row to the output file and printing\n",
    "            for row in results:\n",
    "                line = str(row) + '\\n'\n",
    "                output_file.write(line)\n",
    "                print(line.strip())  # Print each row\n",
    "\n",
    "def main():\n",
    "    # Defining the path for saving query results\n",
    "    results_path = '../Results/district_dimension_query_results.txt' \n",
    "    \n",
    "    # Opening the output file in write mode\n",
    "    with open(results_path, 'w') as output_file:\n",
    "\n",
    "        # Iterating through each query and running it\n",
    "        for description, query in queries.items():\n",
    "            \n",
    "            # Writing and printing the message for the running query\n",
    "            message = f\"Running {description}...\\n\"\n",
    "            output_file.write(message)\n",
    "            print(message.strip())  # Print the running message\n",
    "\n",
    "            # Executing the SQL query\n",
    "            execute_query(query, output_file)\n",
    "\n",
    "            # Writing and printing the completion message after the query execution\n",
    "            completed_message = f\"Completed {description}\\n\\n\"\n",
    "            output_file.write(completed_message)\n",
    "            print(completed_message.strip())  # Print the completed message\n",
    "\n",
    "# Calling the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "   \n",
    "info_logger.info(\"Testing completed for District dimension\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c9473c9-e913-4385-afc6-acb647cc5284",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:39:10.453034Z",
     "iopub.status.busy": "2024-09-12T12:39:10.453034Z",
     "iopub.status.idle": "2024-09-12T12:39:10.709059Z",
     "shell.execute_reply": "2024-09-12T12:39:10.709059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running record_completeness : property_type_dimension...\n",
      "('Total Records in Dimension', 3504)\n",
      "('Records from Source Table', 3504)\n",
      "Completed record_completeness : property_type_dimension\n",
      "Running null_checks : property_type_dimension...\n",
      "(0, 0, 0, 0, 0, 0, 0, 0)\n",
      "Completed null_checks : property_type_dimension\n",
      "Running duplicate_records_check : property_type_dimension...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed duplicate_records_check : property_type_dimension\n",
      "Running accuracy_check : property_type_dimension...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Records in source not in target', 0)\n",
      "('Records in target not in source', 0)\n",
      "Completed accuracy_check : property_type_dimension\n",
      "Running inactive_records_check : property_type_dimension...\n",
      "Completed inactive_records_check : property_type_dimension\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Database credentials\n",
    "DB_CONFIG = {\n",
    "    'dbname': 'UK Real Estate DB',\n",
    "    'user': 'postgres',\n",
    "    'password': '123!@*qweQWE',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "# Queries to execute\n",
    "queries = {\n",
    "    \"record_completeness : property_type_dimension\": \"\"\"\n",
    "        -- Verify the number of records loaded into the dimension\n",
    "        SELECT \n",
    "            'Total Records in Dimension' AS description,\n",
    "            COUNT(*) AS count\n",
    "        FROM property_type_dimension\n",
    "        UNION ALL\n",
    "        SELECT \n",
    "            'Records from Source Table' AS description,\n",
    "            COUNT(DISTINCT (local_authority_code, date)) AS count\n",
    "        FROM initial_load_etl_source_data;\n",
    "    \"\"\",\n",
    "    \"null_checks : property_type_dimension\": \"\"\"\n",
    "        -- Check for NULL values in essential fields\n",
    "        SELECT\n",
    "          SUM(CASE WHEN local_authority_code IS NULL THEN 1 ELSE 0 END) AS null_local_authority_code,\n",
    "          SUM(CASE WHEN date IS NULL THEN 1 ELSE 0 END) AS null_date,\n",
    "          SUM(CASE WHEN property_type IS NULL THEN 1 ELSE 0 END) AS null_property_type,\n",
    "          SUM(CASE WHEN duration IS NULL THEN 1 ELSE 0 END) AS null_duration,\n",
    "          SUM(CASE WHEN detached_price IS NULL THEN 1 ELSE 0 END) AS null_detached_price,\n",
    "          SUM(CASE WHEN semi_detached_price IS NULL THEN 1 ELSE 0 END) AS null_semi_detached_price,\n",
    "          SUM(CASE WHEN terraced_price IS NULL THEN 1 ELSE 0 END) AS null_terraced_price,\n",
    "          SUM(CASE WHEN flat_price IS NULL THEN 1 ELSE 0 END) AS null_flat_price\n",
    "        FROM property_type_dimension;\n",
    "    \"\"\",\n",
    "    \"duplicate_records_check : property_type_dimension\": \"\"\"\n",
    "        -- Check for duplicate records in the dimension\n",
    "       SELECT \n",
    "            local_authority_code, \n",
    "            date,\n",
    "            property_type,\n",
    "            duration,\n",
    "            COUNT(*) AS duplicate_count\n",
    "        FROM \n",
    "            property_type_dimension\n",
    "        GROUP BY \n",
    "            local_authority_code, \n",
    "            date,\n",
    "            property_type,\n",
    "            duration\n",
    "        HAVING \n",
    "            COUNT(*) > 1;\n",
    "    \"\"\",\n",
    "    \"accuracy_check : property_type_dimension\": \"\"\"\n",
    "        -- Check records from source not in target\n",
    "        SELECT 'Records in source not in target' AS description, COUNT(*) AS count\n",
    "        FROM (\n",
    "            SELECT local_authority_code, date, property_type, duration, detached_price, semi_detached_price, terraced_price, flat_price\n",
    "            FROM initial_load_etl_source_data\n",
    "            EXCEPT\n",
    "            SELECT local_authority_code, date, property_type, duration, detached_price, semi_detached_price, terraced_price, flat_price\n",
    "            FROM property_type_dimension\n",
    "        ) AS missing_records\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        -- Check records in target not in source\n",
    "        SELECT 'Records in target not in source' AS description, COUNT(*) AS count\n",
    "        FROM (\n",
    "            SELECT local_authority_code, date, property_type, duration, detached_price, semi_detached_price, terraced_price, flat_price\n",
    "            FROM property_type_dimension\n",
    "            EXCEPT\n",
    "            SELECT local_authority_code, date, property_type, duration, detached_price, semi_detached_price, terraced_price, flat_price\n",
    "            FROM initial_load_etl_source_data\n",
    "        ) AS extra_records;\n",
    "    \"\"\",\n",
    "    \"inactive_records_check : property_type_dimension\": \"\"\"\n",
    "        -- Check that all older records are inactive\n",
    "        SELECT \n",
    "            local_authority_code,\n",
    "            date\n",
    "            is_current\n",
    "        FROM property_type_dimension\n",
    "        WHERE (local_authority_code, date) NOT IN (\n",
    "            SELECT \n",
    "                local_authority_code,\n",
    "                MAX(date)\n",
    "            FROM initial_load_etl_source_data\n",
    "            GROUP BY local_authority_code\n",
    "        ) AND is_current = TRUE;\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "\n",
    "def execute_query(query, output_file):\n",
    "    \"\"\" Executes SQL query and write results to a file, also print the results.\"\"\"\n",
    "    \n",
    "    # Establishing a connection to the database using the provided configuration\n",
    "    with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "        \n",
    "        # Creating a cursor object for executing the query\n",
    "        with conn.cursor() as cur:\n",
    "            \n",
    "            # Executing the provided SQL query\n",
    "            cur.execute(query)\n",
    "            # Fetching all query results\n",
    "            results = cur.fetchall()\n",
    "            \n",
    "            # Iterating through the results, writing each row to the output file and printing\n",
    "            for row in results:\n",
    "                line = str(row) + '\\n'\n",
    "                output_file.write(line)\n",
    "                print(line.strip())  # Print each row\n",
    "\n",
    "def main():\n",
    "    # Defining the path for saving query results\n",
    "    results_path = '../Results/property_type_dimension_query_results.txt'\n",
    "    \n",
    "    # Opening the output file in write mode\n",
    "    with open(results_path, 'w') as output_file:\n",
    "\n",
    "        # Iterating through each query and running it\n",
    "        for description, query in queries.items():\n",
    "            \n",
    "            # Writing and printing the message for the running query\n",
    "            message = f\"Running {description}...\\n\"\n",
    "            output_file.write(message)\n",
    "            print(message.strip())  # Print the running message\n",
    "\n",
    "            # Executing the SQL query\n",
    "            execute_query(query, output_file)\n",
    "\n",
    "            # Writing and printing the completion message after the query execution\n",
    "            completed_message = f\"Completed {description}\\n\\n\"\n",
    "            output_file.write(completed_message)\n",
    "            print(completed_message.strip())  # Print the completed message\n",
    "\n",
    "# Calling the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "info_logger.info(\"Testing completed for Property type dimension\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7ca7de5-d78c-49a3-967d-337e089d97ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:39:10.712896Z",
     "iopub.status.busy": "2024-09-12T12:39:10.712896Z",
     "iopub.status.idle": "2024-09-12T12:39:11.103165Z",
     "shell.execute_reply": "2024-09-12T12:39:11.102155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running record_completeness : education_employment_dimension...\n",
      "('Total Records in Dimension', 3504)\n",
      "('Records from Source Table', 3504)\n",
      "Completed record_completeness : education_employment_dimension\n",
      "Running null_checks : education_employment_dimension...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "Completed null_checks : education_employment_dimension\n",
      "Running duplicate_records_check : education_employment_dimension...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed duplicate_records_check : education_employment_dimension\n",
      "Running accuracy_check : education_employment_dimension...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Records in source not in target', 0)\n",
      "('Records in target not in source', 0)\n",
      "Completed accuracy_check : education_employment_dimension\n",
      "Running inactive_records_check : education_employment_dimension...\n",
      "Completed inactive_records_check : education_employment_dimension\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Database credentials\n",
    "DB_CONFIG = {\n",
    "    'dbname': 'UK Real Estate DB',\n",
    "    'user': 'postgres',\n",
    "    'password': '123!@*qweQWE',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "# Queries to execute\n",
    "queries = {\n",
    "    \"record_completeness : education_employment_dimension\": \"\"\"\n",
    "        -- Verify the number of records loaded into the dimension\n",
    "        SELECT \n",
    "            'Total Records in Dimension' AS description,\n",
    "            COUNT(*) AS count\n",
    "        FROM education_employment_dimension\n",
    "        UNION ALL\n",
    "        SELECT \n",
    "            'Records from Source Table' AS description,\n",
    "            COUNT(DISTINCT (local_authority_code, date)) AS count\n",
    "        FROM initial_load_etl_source_data;\n",
    "    \"\"\",\n",
    "    \"null_checks : education_employment_dimension\": \"\"\"\n",
    "        -- Check for NULL values in essential fields\n",
    "        SELECT\n",
    "          SUM(CASE WHEN local_authority_code IS NULL THEN 1 ELSE 0 END) AS null_local_authority_code,\n",
    "          SUM(CASE WHEN date IS NULL THEN 1 ELSE 0 END) AS null_date,\n",
    "          SUM(CASE WHEN qualification_index_score IS NULL THEN 1 ELSE 0 END) AS null_qualification_index_score,\n",
    "          SUM(CASE WHEN qualification_index_rank IS NULL THEN 1 ELSE 0 END) AS null_qualification_index_rank,\n",
    "          SUM(CASE WHEN no_qualifications IS NULL THEN 1 ELSE 0 END) AS null_no_qualifications,\n",
    "          SUM(CASE WHEN level_1_and_entry_level_qualifications IS NULL THEN 1 ELSE 0 END) AS null_level_1_and_entry_level_qualifications,\n",
    "          SUM(CASE WHEN level_2_qualifications IS NULL THEN 1 ELSE 0 END) AS null_level_2_qualifications,\n",
    "          SUM(CASE WHEN level_3_qualifications IS NULL THEN 1 ELSE 0 END) AS null_level_3_qualifications,\n",
    "          SUM(CASE WHEN apprenticeship IS NULL THEN 1 ELSE 0 END) AS null_apprenticeship,\n",
    "          SUM(CASE WHEN level_4_qualifications_and_above IS NULL THEN 1 ELSE 0 END) AS null_level_4_qualifications_and_above,\n",
    "          SUM(CASE WHEN other_qualifications IS NULL THEN 1 ELSE 0 END) AS null_other_qualifications,\n",
    "          SUM(CASE WHEN num_aged_16_plus_unemployed IS NULL THEN 1 ELSE 0 END) AS null_num_aged_16_plus_unemployed,\n",
    "          SUM(CASE WHEN num_aged_16_plus_employed IS NULL THEN 1 ELSE 0 END) AS null_num_aged_16_plus_employed,\n",
    "          SUM(CASE WHEN num_aged_16_plus_self_employed IS NULL THEN 1 ELSE 0 END) AS null_num_aged_16_plus_self_employed,\n",
    "          SUM(CASE WHEN deprivation_average_score IS NULL THEN 1 ELSE 0 END) AS null_deprivation_average_score,\n",
    "          SUM(CASE WHEN deprivation_employment_ratio IS NULL THEN 1 ELSE 0 END) AS null_deprivation_employment_ratio,\n",
    "          SUM(CASE WHEN qualification_adjusted_employment_rate IS NULL THEN 1 ELSE 0 END) AS null_qualification_adjusted_employment_rate\n",
    "        FROM education_employment_dimension;\n",
    "    \"\"\",\n",
    "    \"duplicate_records_check : education_employment_dimension\": \"\"\"\n",
    "        -- Check for duplicate records in the dimension\n",
    "       SELECT \n",
    "            local_authority_code, \n",
    "            date,\n",
    "            COUNT(*) AS duplicate_count\n",
    "        FROM \n",
    "            education_employment_dimension\n",
    "        GROUP BY \n",
    "            local_authority_code, \n",
    "            date\n",
    "        HAVING \n",
    "            COUNT(*) > 1;\n",
    "    \"\"\",\n",
    "    \"accuracy_check : education_employment_dimension\": \"\"\"\n",
    "        -- Check records from source not in target\n",
    "        SELECT 'Records in source not in target' AS description, COUNT(*) AS count\n",
    "        FROM (\n",
    "            SELECT local_authority_code, date, qualification_index_score, qualification_index_rank, no_qualifications, level_1_and_entry_level_qualifications,\n",
    "                   level_2_qualifications, level_3_qualifications, apprenticeship, level_4_qualifications_and_above, other_qualifications,\n",
    "                   num_aged_16_plus_unemployed, num_aged_16_plus_employed, num_aged_16_plus_self_employed, deprivation_average_score, \n",
    "                   deprivation_employment_ratio, qualification_adjusted_employment_rate\n",
    "            FROM initial_load_etl_source_data\n",
    "            EXCEPT\n",
    "            SELECT local_authority_code, date, qualification_index_score, qualification_index_rank, no_qualifications, level_1_and_entry_level_qualifications,\n",
    "                   level_2_qualifications, level_3_qualifications, apprenticeship, level_4_qualifications_and_above, other_qualifications,\n",
    "                   num_aged_16_plus_unemployed, num_aged_16_plus_employed, num_aged_16_plus_self_employed, deprivation_average_score, \n",
    "                   deprivation_employment_ratio, qualification_adjusted_employment_rate\n",
    "            FROM education_employment_dimension\n",
    "        ) AS missing_records\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        -- Check records in target not in source\n",
    "        SELECT 'Records in target not in source' AS description, COUNT(*) AS count\n",
    "        FROM (\n",
    "            SELECT local_authority_code, date, qualification_index_score, qualification_index_rank, no_qualifications, level_1_and_entry_level_qualifications,\n",
    "                   level_2_qualifications, level_3_qualifications, apprenticeship, level_4_qualifications_and_above, other_qualifications,\n",
    "                   num_aged_16_plus_unemployed, num_aged_16_plus_employed, num_aged_16_plus_self_employed, deprivation_average_score, \n",
    "                   deprivation_employment_ratio, qualification_adjusted_employment_rate\n",
    "            FROM education_employment_dimension\n",
    "            EXCEPT\n",
    "            SELECT local_authority_code, date, qualification_index_score, qualification_index_rank, no_qualifications, level_1_and_entry_level_qualifications,\n",
    "                   level_2_qualifications, level_3_qualifications, apprenticeship, level_4_qualifications_and_above, other_qualifications,\n",
    "                   num_aged_16_plus_unemployed, num_aged_16_plus_employed, num_aged_16_plus_self_employed, deprivation_average_score, \n",
    "                   deprivation_employment_ratio, qualification_adjusted_employment_rate\n",
    "            FROM initial_load_etl_source_data\n",
    "        ) AS extra_records;\n",
    "    \"\"\",\n",
    "    \"inactive_records_check : education_employment_dimension\": \"\"\"\n",
    "        -- Check that all older records are inactive\n",
    "        SELECT \n",
    "            local_authority_code,\n",
    "            date,\n",
    "            is_current\n",
    "        FROM education_employment_dimension\n",
    "        WHERE (local_authority_code, date) NOT IN (\n",
    "            SELECT \n",
    "                local_authority_code,\n",
    "                MAX(date)\n",
    "            FROM initial_load_etl_source_data\n",
    "            GROUP BY local_authority_code\n",
    "        ) AND is_current = TRUE;\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "\n",
    "def execute_query(query, output_file):\n",
    "    \"\"\" Executes SQL query and write results to a file, also print the results.\"\"\"\n",
    "    \n",
    "    # Establishing a connection to the database using the provided configuration\n",
    "    with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "        \n",
    "        # Creating a cursor object for executing the query\n",
    "        with conn.cursor() as cur:\n",
    "            \n",
    "            # Executing the provided SQL query\n",
    "            cur.execute(query)\n",
    "            # Fetching all query results\n",
    "            results = cur.fetchall()\n",
    "            \n",
    "            # Iterating through the results, writing each row to the output file and printing\n",
    "            for row in results:\n",
    "                line = str(row) + '\\n'\n",
    "                output_file.write(line)\n",
    "                print(line.strip())  # Print each row\n",
    "\n",
    "def main():\n",
    "    # Defining the path for saving query results\n",
    "    results_path = '../Results/education_employment_dimension_query_results.txt'\n",
    "    \n",
    "    # Opening the output file in write mode\n",
    "    with open(results_path, 'w') as output_file:\n",
    "\n",
    "        # Iterating through each query and running it\n",
    "        for description, query in queries.items():\n",
    "            \n",
    "            # Writing and printing the message for the running query\n",
    "            message = f\"Running {description}...\\n\"\n",
    "            output_file.write(message)\n",
    "            print(message.strip())  # Print the running message\n",
    "\n",
    "            # Executing the SQL query\n",
    "            execute_query(query, output_file)\n",
    "\n",
    "            # Writing and printing the completion message after the query execution\n",
    "            completed_message = f\"Completed {description}\\n\\n\"\n",
    "            output_file.write(completed_message)\n",
    "            print(completed_message.strip())  # Print the completed message\n",
    "\n",
    "# Calling the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "   \n",
    "info_logger.info(\"Testing completed for Education Employment dimension\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07d83b78-b3e3-430c-b8bd-b51808bcbdcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:39:11.108480Z",
     "iopub.status.busy": "2024-09-12T12:39:11.108480Z",
     "iopub.status.idle": "2024-09-12T12:39:11.323479Z",
     "shell.execute_reply": "2024-09-12T12:39:11.323479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running record_completeness : demographics_dimension...\n",
      "('Total Records in Dimension', 3504)\n",
      "('Records from Source Table', 3504)\n",
      "Completed record_completeness : demographics_dimension\n",
      "Running null_checks : demographics_dimension...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "Completed null_checks : demographics_dimension\n",
      "Running duplicate_records_check : demographics_dimension...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed duplicate_records_check : demographics_dimension\n",
      "Running accuracy_check : demographics_dimension...\n",
      "('Records in source not in target', 0)\n",
      "('Records in target not in source', 0)\n",
      "Completed accuracy_check : demographics_dimension\n",
      "Running inactive_records_check : demographics_dimension...\n",
      "Completed inactive_records_check : demographics_dimension\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Database credentials\n",
    "DB_CONFIG = {\n",
    "    'dbname': 'UK Real Estate DB',\n",
    "    'user': 'postgres',\n",
    "    'password': '123!@*qweQWE',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "# Queries to execute\n",
    "queries = {\n",
    "    \"record_completeness : demographics_dimension\": \"\"\"\n",
    "        -- Verify the number of records loaded into the dimension\n",
    "        SELECT \n",
    "            'Total Records in Dimension' AS description,\n",
    "            COUNT(*) AS count\n",
    "        FROM demographics_dimension\n",
    "        UNION ALL\n",
    "        SELECT \n",
    "            'Records from Source Table' AS description,\n",
    "            COUNT(DISTINCT (local_authority_code, date)) AS count\n",
    "        FROM initial_load_etl_source_data;\n",
    "    \"\"\",\n",
    "    \"null_checks : demographics_dimension\": \"\"\"\n",
    "        -- Check for NULL values in essential fields\n",
    "        SELECT\n",
    "          SUM(CASE WHEN local_authority_code IS NULL THEN 1 ELSE 0 END) AS null_local_authority_code,\n",
    "          SUM(CASE WHEN date IS NULL THEN 1 ELSE 0 END) AS null_date,\n",
    "          SUM(CASE WHEN area_sq_km IS NULL THEN 1 ELSE 0 END) AS null_area_sq_km,\n",
    "          SUM(CASE WHEN age_0_20 IS NULL THEN 1 ELSE 0 END) AS null_age_0_20,\n",
    "          SUM(CASE WHEN age_20_40 IS NULL THEN 1 ELSE 0 END) AS null_age_20_40,\n",
    "          SUM(CASE WHEN age_40_60 IS NULL THEN 1 ELSE 0 END) AS null_age_40_60,\n",
    "          SUM(CASE WHEN age_60_plus IS NULL THEN 1 ELSE 0 END) AS null_age_60_plus,\n",
    "          SUM(CASE WHEN female_population IS NULL THEN 1 ELSE 0 END) AS null_female_population,\n",
    "          SUM(CASE WHEN all_ages IS NULL THEN 1 ELSE 0 END) AS null_all_ages,\n",
    "          SUM(CASE WHEN male_population IS NULL THEN 1 ELSE 0 END) AS null_male_population,\n",
    "          SUM(CASE WHEN est_num_households_with_child IS NULL THEN 1 ELSE 0 END) AS null_est_num_households_with_child,\n",
    "          SUM(CASE WHEN age_dependency_ratio IS NULL THEN 1 ELSE 0 END) AS null_age_dependency_ratio\n",
    "        FROM demographics_dimension;\n",
    "    \"\"\",\n",
    "    \"duplicate_records_check : demographics_dimension\": \"\"\"\n",
    "        -- Check for duplicate records in the dimension\n",
    "        SELECT \n",
    "            local_authority_code, \n",
    "            date,\n",
    "            COUNT(*) AS duplicate_count\n",
    "        FROM \n",
    "            demographics_dimension\n",
    "        GROUP BY \n",
    "            local_authority_code, \n",
    "            date\n",
    "        HAVING \n",
    "            COUNT(*) > 1;\n",
    "    \"\"\",\n",
    "    \"accuracy_check : demographics_dimension\": \"\"\"\n",
    "        -- Check records from source not in target\n",
    "        SELECT 'Records in source not in target' AS description, COUNT(*) AS count\n",
    "        FROM (\n",
    "            SELECT local_authority_code, date, area_sq_km, age_0_20, age_20_40, age_40_60, age_60_plus,\n",
    "                   female_population, all_ages, male_population, est_num_households_with_child, age_dependency_ratio\n",
    "            FROM initial_load_etl_source_data\n",
    "            EXCEPT\n",
    "            SELECT local_authority_code, date, area_sq_km, age_0_20, age_20_40, age_40_60, age_60_plus,\n",
    "                   female_population, all_ages, male_population, est_num_households_with_child, age_dependency_ratio\n",
    "            FROM demographics_dimension\n",
    "        ) AS missing_records\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        -- Check records in target not in source\n",
    "        SELECT 'Records in target not in source' AS description, COUNT(*) AS count\n",
    "        FROM (\n",
    "            SELECT local_authority_code, date, area_sq_km, age_0_20, age_20_40, age_40_60, age_60_plus,\n",
    "                   female_population, all_ages, male_population, est_num_households_with_child, age_dependency_ratio\n",
    "            FROM demographics_dimension\n",
    "            EXCEPT\n",
    "            SELECT local_authority_code, date, area_sq_km, age_0_20, age_20_40, age_40_60, age_60_plus,\n",
    "                   female_population, all_ages, male_population, est_num_households_with_child, age_dependency_ratio\n",
    "            FROM initial_load_etl_source_data\n",
    "        ) AS extra_records;\n",
    "    \"\"\",\n",
    "    \"inactive_records_check : demographics_dimension\": \"\"\"\n",
    "        -- Check that all older records are inactive\n",
    "        SELECT \n",
    "            local_authority_code,\n",
    "            date,\n",
    "            is_current\n",
    "        FROM demographics_dimension\n",
    "        WHERE (local_authority_code, date) NOT IN (\n",
    "            SELECT \n",
    "                local_authority_code,\n",
    "                MAX(date)\n",
    "            FROM initial_load_etl_source_data\n",
    "            GROUP BY local_authority_code\n",
    "        ) AND is_current = TRUE;\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "def execute_query(query, output_file):\n",
    "    \"\"\" Executes SQL query and write results to a file, also print the results.\"\"\"\n",
    "    \n",
    "    # Establishing a connection to the database using the provided configuration\n",
    "    with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "        \n",
    "        # Creating a cursor object for executing the query\n",
    "        with conn.cursor() as cur:\n",
    "            \n",
    "            # Executing the provided SQL query\n",
    "            cur.execute(query)\n",
    "            # Fetching all query results\n",
    "            results = cur.fetchall()\n",
    "            \n",
    "            # Iterating through the results, writing each row to the output file and printing\n",
    "            for row in results:\n",
    "                line = str(row) + '\\n'\n",
    "                output_file.write(line)\n",
    "                print(line.strip())  # Print each row\n",
    "\n",
    "def main():\n",
    "    # Defining the path for saving query results\n",
    "    results_path = '../Results/demographics_dimension_query_results.txt' \n",
    "    \n",
    "    # Opening the output file in write mode\n",
    "    with open(results_path, 'w') as output_file:\n",
    "\n",
    "        # Iterating through each query and running it\n",
    "        for description, query in queries.items():\n",
    "            \n",
    "            # Writing and printing the message for the running query\n",
    "            message = f\"Running {description}...\\n\"\n",
    "            output_file.write(message)\n",
    "            print(message.strip())  # Print the running message\n",
    "\n",
    "            # Executing the SQL query\n",
    "            execute_query(query, output_file)\n",
    "\n",
    "            # Writing and printing the completion message after the query execution\n",
    "            completed_message = f\"Completed {description}\\n\\n\"\n",
    "            output_file.write(completed_message)\n",
    "            print(completed_message.strip())  # Print the completed message\n",
    "\n",
    "# Calling the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "info_logger.info(\"Testing completed for Demographics dimension\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d34264f9-f1e4-4cd5-8b62-0dbc0ffbe95f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:39:11.326525Z",
     "iopub.status.busy": "2024-09-12T12:39:11.326525Z",
     "iopub.status.idle": "2024-09-12T12:39:11.590796Z",
     "shell.execute_reply": "2024-09-12T12:39:11.590796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running record_completeness : rental_dimension...\n",
      "('Total Records in Dimension', 3504)\n",
      "('Records from Source Table', 3504)\n",
      "Completed record_completeness : rental_dimension\n",
      "Running null_checks : rental_dimension...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 0, 0, 0, 0, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed null_checks : rental_dimension\n",
      "Running duplicate_records_check : rental_dimension...\n",
      "Completed duplicate_records_check : rental_dimension\n",
      "Running accuracy_check : rental_dimension...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Records in source not in target', 0)\n",
      "('Records in target not in source', 0)\n",
      "Completed accuracy_check : rental_dimension\n",
      "Running inactive_records_check : rental_dimension...\n",
      "Completed inactive_records_check : rental_dimension\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Database credentials\n",
    "DB_CONFIG = {\n",
    "    'dbname': 'UK Real Estate DB',\n",
    "    'user': 'postgres',\n",
    "    'password': '123!@*qweQWE',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "# Queries to execute\n",
    "queries = {\n",
    "    \"record_completeness : rental_dimension\": \"\"\"\n",
    "        -- Verify the number of records loaded into the dimension\n",
    "        SELECT \n",
    "            'Total Records in Dimension' AS description,\n",
    "            COUNT(*) AS count\n",
    "        FROM rental_dimension\n",
    "        UNION ALL\n",
    "        SELECT \n",
    "            'Records from Source Table' AS description,\n",
    "            COUNT(DISTINCT (local_authority_code, date)) AS count\n",
    "        FROM initial_load_etl_source_data;\n",
    "    \"\"\",\n",
    "    \"null_checks : rental_dimension\": \"\"\"\n",
    "        -- Check for NULL values in essential fields\n",
    "        SELECT\n",
    "          SUM(CASE WHEN local_authority_code IS NULL THEN 1 ELSE 0 END) AS null_local_authority_code,\n",
    "          SUM(CASE WHEN date IS NULL THEN 1 ELSE 0 END) AS null_date,\n",
    "          SUM(CASE WHEN rental_price IS NULL THEN 1 ELSE 0 END) AS null_rental_price,\n",
    "          SUM(CASE WHEN one_bedroom_rent IS NULL THEN 1 ELSE 0 END) AS null_one_bedroom_rent,\n",
    "          SUM(CASE WHEN two_bedrooms_rent IS NULL THEN 1 ELSE 0 END) AS null_two_bedrooms_rent,\n",
    "          SUM(CASE WHEN three_bedrooms_rent IS NULL THEN 1 ELSE 0 END) AS null_three_bedrooms_rent,\n",
    "          SUM(CASE WHEN four_or_more_bedrooms_rent IS NULL THEN 1 ELSE 0 END) AS null_four_or_more_bedrooms_rent,\n",
    "          SUM(CASE WHEN all_categories_rent IS NULL THEN 1 ELSE 0 END) AS null_all_categories_rent\n",
    "        FROM rental_dimension;\n",
    "    \"\"\",\n",
    "    \"duplicate_records_check : rental_dimension\": \"\"\"\n",
    "        -- Check for duplicate records in the dimension\n",
    "        SELECT \n",
    "            local_authority_code, \n",
    "            date,\n",
    "            COUNT(*) AS duplicate_count\n",
    "        FROM \n",
    "            rental_dimension\n",
    "        GROUP BY \n",
    "            local_authority_code, \n",
    "            date\n",
    "        HAVING \n",
    "            COUNT(*) > 1;\n",
    "    \"\"\",\n",
    "    \"accuracy_check : rental_dimension\": \"\"\"\n",
    "        -- Check records from source not in target\n",
    "        SELECT 'Records in source not in target' AS description, COUNT(*) AS count\n",
    "        FROM (\n",
    "            SELECT local_authority_code, date, rental_price, one_bedroom_rent, two_bedrooms_rent, three_bedrooms_rent, \n",
    "                   four_or_more_bedrooms_rent, all_categories_rent\n",
    "            FROM initial_load_etl_source_data\n",
    "            EXCEPT\n",
    "            SELECT local_authority_code, date, rental_price, one_bedroom_rent, two_bedrooms_rent, three_bedrooms_rent, \n",
    "                   four_or_more_bedrooms_rent, all_categories_rent\n",
    "            FROM rental_dimension\n",
    "        ) AS missing_records\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        -- Check records in target not in source\n",
    "        SELECT 'Records in target not in source' AS description, COUNT(*) AS count\n",
    "        FROM (\n",
    "            SELECT local_authority_code, date, rental_price, one_bedroom_rent, two_bedrooms_rent, three_bedrooms_rent, \n",
    "                   four_or_more_bedrooms_rent, all_categories_rent\n",
    "            FROM rental_dimension\n",
    "            EXCEPT\n",
    "            SELECT local_authority_code, date, rental_price, one_bedroom_rent, two_bedrooms_rent, three_bedrooms_rent, \n",
    "                   four_or_more_bedrooms_rent, all_categories_rent\n",
    "            FROM initial_load_etl_source_data\n",
    "        ) AS extra_records;\n",
    "    \"\"\",\n",
    "    \"inactive_records_check : rental_dimension\": \"\"\"\n",
    "        -- Check that all older records are inactive\n",
    "        SELECT \n",
    "            local_authority_code,\n",
    "            date,\n",
    "            is_current\n",
    "        FROM rental_dimension\n",
    "        WHERE (local_authority_code, date) NOT IN (\n",
    "            SELECT \n",
    "                local_authority_code,\n",
    "                MAX(date)\n",
    "            FROM initial_load_etl_source_data\n",
    "            GROUP BY local_authority_code\n",
    "        ) AND is_current = TRUE;\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "def execute_query(query, output_file):\n",
    "    \"\"\" Executes SQL query and write results to a file, also print the results.\"\"\"\n",
    "    \n",
    "    # Establishing a connection to the database using the provided configuration\n",
    "    with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "        \n",
    "        # Creating a cursor object for executing the query\n",
    "        with conn.cursor() as cur:\n",
    "            \n",
    "            # Executing the provided SQL query\n",
    "            cur.execute(query)\n",
    "            # Fetching all query results\n",
    "            results = cur.fetchall()\n",
    "            \n",
    "            # Iterating through the results, writing each row to the output file and printing\n",
    "            for row in results:\n",
    "                line = str(row) + '\\n'\n",
    "                output_file.write(line)\n",
    "                print(line.strip())  # Print each row\n",
    "\n",
    "def main():\n",
    "    # Defining the path for saving query results\n",
    "    results_path = '../Results/rental_dimension_query_results.txt' \n",
    "    \n",
    "    # Opening the output file in write mode\n",
    "    with open(results_path, 'w') as output_file:\n",
    "\n",
    "        # Iterating through each query and running it\n",
    "        for description, query in queries.items():\n",
    "            \n",
    "            # Writing and printing the message for the running query\n",
    "            message = f\"Running {description}...\\n\"\n",
    "            output_file.write(message)\n",
    "            print(message.strip())  # Print the running message\n",
    "\n",
    "            # Executing the SQL query\n",
    "            execute_query(query, output_file)\n",
    "\n",
    "            # Writing and printing the completion message after the query execution\n",
    "            completed_message = f\"Completed {description}\\n\\n\"\n",
    "            output_file.write(completed_message)\n",
    "            print(completed_message.strip())  # Print the completed message\n",
    "\n",
    "# Calling the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "info_logger.info(\"Testing completed for Rental dimension\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53a08019-4ce6-4542-8446-504785031c10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:39:11.597195Z",
     "iopub.status.busy": "2024-09-12T12:39:11.596193Z",
     "iopub.status.idle": "2024-09-12T12:39:11.870399Z",
     "shell.execute_reply": "2024-09-12T12:39:11.870399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running record_completeness : sales_transactions_fact...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total Records in Fact Table', 3504)\n",
      "('Records from Source Table', 3504)\n",
      "Completed record_completeness : sales_transactions_fact\n",
      "Running null_checks : sales_transactions_fact...\n",
      "(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "Completed null_checks : sales_transactions_fact\n",
      "Running duplicate_records_check : sales_transactions_fact...\n",
      "Completed duplicate_records_check : sales_transactions_fact\n",
      "Running accuracy_check : sales_transactions_fact...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Records in source not in target', 0)\n",
      "('Records in target not in source', 0)\n",
      "Completed accuracy_check : sales_transactions_fact\n",
      "Running inactive_records_check : sales_transactions_fact...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed inactive_records_check : sales_transactions_fact\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Database credentials\n",
    "DB_CONFIG = {\n",
    "    'dbname': 'UK Real Estate DB',\n",
    "    'user': 'postgres',\n",
    "    'password': '123!@*qweQWE',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "# Queries to execute\n",
    "queries = {\n",
    "    \"record_completeness : sales_transactions_fact\": \"\"\"\n",
    "        -- Verify the number of records loaded into the fact table\n",
    "        SELECT \n",
    "            'Total Records in Fact Table' AS description,\n",
    "            COUNT(*) AS count\n",
    "        FROM sales_transactions_fact\n",
    "        UNION ALL\n",
    "        SELECT \n",
    "            'Records from Source Table' AS description,\n",
    "            COUNT(DISTINCT (local_authority_code, date)) AS count\n",
    "        FROM initial_load_etl_source_data;\n",
    "    \"\"\",\n",
    "    \"null_checks : sales_transactions_fact\": \"\"\"\n",
    "        -- Check for NULL values in essential fields\n",
    "        SELECT\n",
    "          SUM(CASE WHEN local_authority_code IS NULL THEN 1 ELSE 0 END) AS null_local_authority_code,\n",
    "          SUM(CASE WHEN date IS NULL THEN 1 ELSE 0 END) AS null_date,\n",
    "          SUM(CASE WHEN district_id IS NULL THEN 1 ELSE 0 END) AS null_district_id,\n",
    "          SUM(CASE WHEN region_id IS NULL THEN 1 ELSE 0 END) AS null_region_id,\n",
    "          SUM(CASE WHEN property_type_id IS NULL THEN 1 ELSE 0 END) AS null_property_type_id,\n",
    "          SUM(CASE WHEN vehicle_id IS NULL THEN 1 ELSE 0 END) AS null_vehicle_id,\n",
    "          SUM(CASE WHEN rental_id IS NULL THEN 1 ELSE 0 END) AS null_rental_id,\n",
    "          SUM(CASE WHEN demographics_id IS NULL THEN 1 ELSE 0 END) AS null_demographics_id,\n",
    "          SUM(CASE WHEN education_employment_id IS NULL THEN 1 ELSE 0 END) AS null_education_employment_id,\n",
    "          SUM(CASE WHEN date_key IS NULL THEN 1 ELSE 0 END) AS null_date_key,\n",
    "          SUM(CASE WHEN price IS NULL THEN 1 ELSE 0 END) AS null_price,\n",
    "          SUM(CASE WHEN average_price IS NULL THEN 1 ELSE 0 END) AS null_average_price,\n",
    "          SUM(CASE WHEN predicted_price_unscaled IS NULL THEN 1 ELSE 0 END) AS null_predicted_price_unscaled,\n",
    "          SUM(CASE WHEN index IS NULL THEN 1 ELSE 0 END) AS null_index,\n",
    "          SUM(CASE WHEN average_price_pct_change IS NULL THEN 1 ELSE 0 END) AS null_average_price_pct_change,\n",
    "          SUM(CASE WHEN annual_change_percent IS NULL THEN 1 ELSE 0 END) AS null_annual_change_percent,\n",
    "          SUM(CASE WHEN new_price IS NULL THEN 1 ELSE 0 END) AS null_new_price,\n",
    "          SUM(CASE WHEN old_price IS NULL THEN 1 ELSE 0 END) AS null_old_price,\n",
    "          SUM(CASE WHEN sales_volume IS NULL THEN 1 ELSE 0 END) AS null_sales_volume,\n",
    "          SUM(CASE WHEN sales_volume_log IS NULL THEN 1 ELSE 0 END) AS null_sales_volume_log,\n",
    "          SUM(CASE WHEN old_sales_volume IS NULL THEN 1 ELSE 0 END) AS null_old_sales_volume,\n",
    "          SUM(CASE WHEN detached_flat_ratio IS NULL THEN 1 ELSE 0 END) AS null_detached_flat_ratio,\n",
    "          SUM(CASE WHEN detached_terraced_ratio IS NULL THEN 1 ELSE 0 END) AS null_detached_terraced_ratio,\n",
    "          SUM(CASE WHEN semi_detached_price_pct_change IS NULL THEN 1 ELSE 0 END) AS null_semi_detached_price_pct_change,\n",
    "          SUM(CASE WHEN detached_semi_detached_ratio IS NULL THEN 1 ELSE 0 END) AS null_detached_semi_detached_ratio,\n",
    "          SUM(CASE WHEN detached_price_log IS NULL THEN 1 ELSE 0 END) AS null_detached_price_log,\n",
    "          SUM(CASE WHEN semi_detached_price_log IS NULL THEN 1 ELSE 0 END) AS null_semi_detached_price_log,\n",
    "          SUM(CASE WHEN flat_price_log IS NULL THEN 1 ELSE 0 END) AS null_flat_price_log,\n",
    "          SUM(CASE WHEN terraced_price_pct_change IS NULL THEN 1 ELSE 0 END) AS null_terraced_price_pct_change,\n",
    "          SUM(CASE WHEN terraced_price_log IS NULL THEN 1 ELSE 0 END) AS null_terraced_price_log,\n",
    "          SUM(CASE WHEN gdhi IS NULL THEN 1 ELSE 0 END) AS null_gdhi,\n",
    "          SUM(CASE WHEN deprivation_adjusted_gdhi IS NULL THEN 1 ELSE 0 END) AS null_deprivation_adjusted_gdhi,\n",
    "          SUM(CASE WHEN gdhi_per_capita IS NULL THEN 1 ELSE 0 END) AS null_gdhi_per_capita,\n",
    "          SUM(CASE WHEN foo_price IS NULL THEN 1 ELSE 0 END) AS null_foo_price,\n",
    "          SUM(CASE WHEN cash_price IS NULL THEN 1 ELSE 0 END) AS null_cash_price,\n",
    "          SUM(CASE WHEN mortgage_price IS NULL THEN 1 ELSE 0 END) AS null_mortgage_price,\n",
    "          SUM(CASE WHEN housing_demand_indicator IS NULL THEN 1 ELSE 0 END) AS null_housing_demand_indicator,\n",
    "          SUM(CASE WHEN deprivation_reduction_potential IS NULL THEN 1 ELSE 0 END) AS null_deprivation_reduction_potential,\n",
    "          SUM(CASE WHEN flat_price_pct_change IS NULL THEN 1 ELSE 0 END) AS null_flat_price_pct_change,\n",
    "          SUM(CASE WHEN detached_price_pct_change IS NULL THEN 1 ELSE 0 END) AS null_detached_price_pct_change,\n",
    "          SUM(CASE WHEN average_price_log IS NULL THEN 1 ELSE 0 END) AS null_average_price_log,\n",
    "          SUM(CASE WHEN ftb_price IS NULL THEN 1 ELSE 0 END) AS null_ftb_price\n",
    "        FROM sales_transactions_fact;\n",
    "    \"\"\",\n",
    "    \"duplicate_records_check : sales_transactions_fact\": \"\"\"\n",
    "        -- Check for duplicate records in the fact\n",
    "        SELECT \n",
    "            local_authority_code, \n",
    "            date,\n",
    "            COUNT(*) AS duplicate_count\n",
    "        FROM \n",
    "            sales_transactions_fact\n",
    "        GROUP BY \n",
    "            local_authority_code, \n",
    "            date\n",
    "        HAVING \n",
    "            COUNT(*) > 1;\n",
    "    \"\"\",\n",
    "    \"accuracy_check : sales_transactions_fact\": \"\"\"\n",
    "        -- Check records from source not in target\n",
    "        SELECT 'Records in source not in target' AS description, COUNT(*) AS count\n",
    "        FROM (\n",
    "            SELECT local_authority_code, date, price, average_price, predicted_price_unscaled, index, average_price_pct_change,\n",
    "                   annual_change_percent, new_price, old_price, sales_volume, sales_volume_log, old_sales_volume, detached_flat_ratio,\n",
    "                   detached_terraced_ratio, semi_detached_price_pct_change, detached_semi_detached_ratio, detached_price_log, \n",
    "                   semi_detached_price_log, flat_price_log, terraced_price_pct_change, terraced_price_log, gdhi, deprivation_adjusted_gdhi,\n",
    "                   gdhi_per_capita, foo_price, cash_price, mortgage_price, housing_demand_indicator, deprivation_reduction_potential, \n",
    "                   flat_price_pct_change, detached_price_pct_change, average_price_log, ftb_price\n",
    "            FROM initial_load_etl_source_data\n",
    "            EXCEPT\n",
    "            SELECT local_authority_code, date, price, average_price, predicted_price_unscaled, index, average_price_pct_change,\n",
    "                   annual_change_percent, new_price, old_price, sales_volume, sales_volume_log, old_sales_volume, detached_flat_ratio,\n",
    "                   detached_terraced_ratio, semi_detached_price_pct_change, detached_semi_detached_ratio, detached_price_log, \n",
    "                   semi_detached_price_log, flat_price_log, terraced_price_pct_change, terraced_price_log, gdhi, deprivation_adjusted_gdhi,\n",
    "                   gdhi_per_capita, foo_price, cash_price, mortgage_price, housing_demand_indicator, deprivation_reduction_potential, \n",
    "                   flat_price_pct_change, detached_price_pct_change, average_price_log, ftb_price\n",
    "            FROM sales_transactions_fact\n",
    "        ) AS missing_records\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        -- Check records in target not in source\n",
    "        SELECT 'Records in target not in source' AS description, COUNT(*) AS count\n",
    "        FROM (\n",
    "            SELECT local_authority_code, date, price, average_price, predicted_price_unscaled, index, average_price_pct_change,\n",
    "                   annual_change_percent, new_price, old_price, sales_volume, sales_volume_log, old_sales_volume, detached_flat_ratio,\n",
    "                   detached_terraced_ratio, semi_detached_price_pct_change, detached_semi_detached_ratio, detached_price_log, \n",
    "                   semi_detached_price_log, flat_price_log, terraced_price_pct_change, terraced_price_log, gdhi, deprivation_adjusted_gdhi,\n",
    "                   gdhi_per_capita, foo_price, cash_price, mortgage_price, housing_demand_indicator, deprivation_reduction_potential, \n",
    "                   flat_price_pct_change, detached_price_pct_change, average_price_log, ftb_price\n",
    "            FROM sales_transactions_fact\n",
    "            EXCEPT\n",
    "            SELECT local_authority_code, date, price, average_price, predicted_price_unscaled, index, average_price_pct_change,\n",
    "                   annual_change_percent, new_price, old_price, sales_volume, sales_volume_log, old_sales_volume, detached_flat_ratio,\n",
    "                   detached_terraced_ratio, semi_detached_price_pct_change, detached_semi_detached_ratio, detached_price_log, \n",
    "                   semi_detached_price_log, flat_price_log, terraced_price_pct_change, terraced_price_log, gdhi, deprivation_adjusted_gdhi,\n",
    "                   gdhi_per_capita, foo_price, cash_price, mortgage_price, housing_demand_indicator, deprivation_reduction_potential, \n",
    "                   flat_price_pct_change, detached_price_pct_change, average_price_log, ftb_price\n",
    "            FROM initial_load_etl_source_data\n",
    "        ) AS extra_records;\n",
    "    \"\"\",\n",
    "    \"inactive_records_check : sales_transactions_fact\": \"\"\"\n",
    "        -- Check that all older records are inactive\n",
    "        SELECT \n",
    "            local_authority_code,\n",
    "            date,\n",
    "            is_current\n",
    "        FROM sales_transactions_fact\n",
    "        WHERE (local_authority_code, date) NOT IN (\n",
    "            SELECT \n",
    "                local_authority_code,\n",
    "                MAX(date)\n",
    "            FROM initial_load_etl_source_data\n",
    "            GROUP BY local_authority_code\n",
    "        ) AND is_current = TRUE;\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "def execute_query(query, output_file):\n",
    "    \"\"\" Executes SQL query and write results to a file, also print the results.\"\"\"\n",
    "    \n",
    "    # Establishing a connection to the database using the provided configuration\n",
    "    with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "        \n",
    "        # Creating a cursor object for executing the query\n",
    "        with conn.cursor() as cur:\n",
    "            \n",
    "            # Executing the provided SQL query\n",
    "            cur.execute(query)\n",
    "            # Fetching all query results\n",
    "            results = cur.fetchall()\n",
    "            \n",
    "            # Iterating through the results, writing each row to the output file and printing\n",
    "            for row in results:\n",
    "                line = str(row) + '\\n'\n",
    "                output_file.write(line)\n",
    "                print(line.strip())  # Print each row\n",
    "\n",
    "def main():\n",
    "    # Defining the path for saving query results\n",
    "    results_path = '../Results/sales_fact_query_results.txt' \n",
    "    \n",
    "    # Opening the output file in write mode\n",
    "    with open(results_path, 'w') as output_file:\n",
    "\n",
    "        # Iterating through each query and running it\n",
    "        for description, query in queries.items():\n",
    "            \n",
    "            # Writing and printing the message for the running query\n",
    "            message = f\"Running {description}...\\n\"\n",
    "            output_file.write(message)\n",
    "            print(message.strip())  # Print the running message\n",
    "\n",
    "            # Executing the SQL query\n",
    "            execute_query(query, output_file)\n",
    "\n",
    "            # Writing and printing the completion message after the query execution\n",
    "            completed_message = f\"Completed {description}\\n\\n\"\n",
    "            output_file.write(completed_message)\n",
    "            print(completed_message.strip())  # Print the completed message\n",
    "\n",
    "# Calling the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "info_logger.info(\"Testing completed for Sales Transaction Fact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2061b92-a97b-4cf2-a618-577aa2b9adc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
