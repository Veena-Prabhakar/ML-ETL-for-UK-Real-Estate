{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3430735f-da03-4b03-b7b8-f82215ca7a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # Importing  Sys module to interact with the Python runtime environment\n",
    "import numpy as np # Importing NumPy is used for numerical operations\n",
    "import pandas as pd # Importing Pandas provides powerful data structures for data analysis\n",
    "import joblib # Importing Joblib for saving and loading models efficiently\n",
    "import psycopg2 # Importing PostgreSQL database adapter for Python\n",
    "from contextlib import contextmanager  # Importing contextmanager for creating context managers\n",
    "from sklearn.ensemble import RandomForestRegressor # Importing RandomForestRegressor for regression tasks\n",
    "from sklearn.impute import SimpleImputer  # Importing SimpleImputer to handle missing values\n",
    "from sklearn.model_selection import train_test_split # Importing train_test_split to split data into train and test sets\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion  # Importing Pipeline and FeatureUnion for creating machine learning workflows\n",
    "from sklearn.compose import ColumnTransformer  # Importing ColumnTransformer for applying transformers to specific columns\n",
    "from sklearn.preprocessing import (  \n",
    "    RobustScaler,  # Importing RobustScaler for scaling features robust to outliers\n",
    "    StandardScaler,  # Importing StandardScaler for standardizing features\n",
    "    OrdinalEncoder,  # Importing OrdinalEncoder for encoding categorical features\n",
    "    FunctionTransformer  # Importing FunctionTransformer for creating custom data transformations\n",
    ")\n",
    "# Suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Path adjustments for modules\n",
    "sys.path.append('../Scripts')\n",
    "\n",
    "# Import custom transformation modules\n",
    "from data_transformations_1 import main_processing_pipeline\n",
    "from data_transformations_2 import GroupMeanImputer, FeatureCreator, EncodingWithNames, ColumnTransformerDf, ColumnOrderTransformer\n",
    "from data_transformations_3 import apply_imputations, prepare_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1614e2d-4396-4eae-9644-15af74ac8dc9",
   "metadata": {},
   "source": [
    "### Preparation of default value list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6089cedc-d9ab-470b-9407-03436d6f96a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             feature    default_value\n",
      "0                                           District             ADUR\n",
      "1                                Transfer Month-Year         Jan-2024\n",
      "2                                          Town/City           LONDON\n",
      "3                                             County   GREATER LONDON\n",
      "4                                              Price  26457690.957171\n",
      "..                                               ...              ...\n",
      "72                                  Petrol LGV total         0.594976\n",
      "73                                     LPG LGV total         0.000306\n",
      "74  Personal transport (buses, cars and motorcycles)         70.43712\n",
      "75                   Freight transport (HGV and LGV)        41.595804\n",
      "76                  Fuel consumption by all vehicles       112.032924\n",
      "\n",
      "[77 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def read_and_prepare_data(data_file_path):\n",
    "    # Load the main dataset\n",
    "    data_df = pd.read_excel(data_file_path)\n",
    "    \n",
    "    # Filtering numeric features\n",
    "    numeric_features = data_df.select_dtypes(include=[np.number])\n",
    "    # Calculating mean for numeric features\n",
    "    numeric_defaults = numeric_features.mean().reset_index()\n",
    "    numeric_defaults.columns = ['feature', 'default_value']\n",
    "\n",
    "    # Filtering non-numeric features\n",
    "    non_numeric_features = data_df.select_dtypes(exclude=[np.number])\n",
    "    # Calculate mode for non-numeric features\n",
    "    non_numeric_defaults = non_numeric_features.mode().iloc[0].reset_index()\n",
    "    non_numeric_defaults.columns = ['feature', 'default_value']\n",
    "\n",
    "    # Merging numeric and non-numeric defaults into one DataFrame\n",
    "    # Using a dictionary to merge defaults by feature\n",
    "    defaults_dict = {}\n",
    "    \n",
    "    for index, row in numeric_defaults.iterrows():\n",
    "        defaults_dict[row['feature']] = row['default_value']\n",
    "    \n",
    "    for index, row in non_numeric_defaults.iterrows():\n",
    "        if row['feature'] not in defaults_dict:\n",
    "            defaults_dict[row['feature']] = row['default_value']\n",
    "    \n",
    "    # Converting the dictionary to a DataFrame\n",
    "    combined_defaults = pd.DataFrame(list(defaults_dict.items()), columns=['feature', 'default_value'])\n",
    "    # Defining the desired column order\n",
    "    desired_order = [\n",
    "        'District', 'Transfer Month-Year', 'Town/City', 'County', 'Price',\n",
    "        'Property Type', 'Old/New', 'Duration', 'PPD Category Type', 'Record Status',\n",
    "        'Region code', 'Region name', 'Local authority code', 'Local authority name',\n",
    "        'Date', 'RegionName', 'AreaCode', 'AveragePrice', 'Index', '1m%Change',\n",
    "        'SalesVolume', 'DetachedPrice', 'SemiDetachedPrice', 'TerracedPrice',\n",
    "        'FlatPrice', 'CashPrice', 'MortgagePrice', 'MortgageIndex', 'FTBPrice',\n",
    "        'FOOPrice', 'NewPrice', 'NewSalesVolume', 'OldPrice', 'OldSalesVolume',\n",
    "        'Annual change (%)', 'Rental price (£)', 'One Bedroom Rent', 'Two Bedrooms Rent',\n",
    "        'Three Bedrooms Rent', 'Four or more Bedrooms Rent', 'All categories Rent',\n",
    "        'All ages', '0-20', '20-40', '40-60', '60+', 'Female population',\n",
    "        'Male population', 'Area (sq km)', 'Qualification index score',\n",
    "        'Qualification index rank (1 to 331)', 'No qualifications',\n",
    "        'Level 1 and entry level qualifications', 'Level 2 qualifications', 'Apprenticeship',\n",
    "        'Level 3 qualifications', 'Level 4 qualifications and above', 'Other qualifications',\n",
    "        'Estimated number of households with at least 1 early-years or school age child',\n",
    "        'Deprivation Average Score', 'Number of those aged 16+ who are unemployed',\n",
    "        'Number of those aged 16+ in employment who are employees',\n",
    "        'Number of those aged 16+ in employment who are self-employed', 'GDHI',\n",
    "        'Number of Schools', 'Headcount of Pupils(school)', 'Buses total',\n",
    "        'Diesel cars total', 'Petrol cars total', 'HGV - Motorways', 'HGV total',\n",
    "        'Diesel LGV total', 'Petrol LGV total', 'LPG LGV total',\n",
    "        'Personal transport (buses, cars and motorcycles)', 'Freight transport (HGV and LGV)',\n",
    "        'Fuel consumption by all vehicles'\n",
    "    ]\n",
    "\n",
    "    # Ensuring the DataFrame has all columns in the desired order\n",
    "    combined_defaults = combined_defaults.set_index('feature').reindex(desired_order).reset_index()\n",
    "    \n",
    "    return combined_defaults\n",
    "\n",
    "# File paths\n",
    "data_file_path = '../Data/Output/original_cleaned_df.xlsx'\n",
    "\n",
    "# Preparing the data\n",
    "default_values_df = read_and_prepare_data(data_file_path)\n",
    "\n",
    "# Saving the combined default values to an Excel file\n",
    "default_values_df.to_excel('../Data/Output/combined_default_values.xlsx', index=False)\n",
    "\n",
    "# Displaying the combined default values DataFrame\n",
    "print(default_values_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0004b0-28a9-49af-bc18-6b941d6d4e3c",
   "metadata": {},
   "source": [
    "### Execution of Price prediction suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e19c404-7e0e-4e78-9949-d935deef0325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter 'Level 4 qualifications and above':  100000\n",
      "Enter '20-40' population:  120000\n",
      "Enter 'Number of those aged 16+ who are unemployed':  10000\n",
      "Enter 'HGV - Motorways':  200000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPredicted Price: £46725795.49\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to make another prediction? (y/n):  y\n",
      "Enter 'Level 4 qualifications and above':  110000\n",
      "Enter '20-40' population:  110000\n",
      "Enter 'Number of those aged 16+ who are unemployed':  5000\n",
      "Enter 'HGV - Motorways':  5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPredicted Price: £45351683.09\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to make another prediction? (y/n):  y\n",
      "Enter 'Level 4 qualifications and above':  1000\n",
      "Enter '20-40' population:  1000\n",
      "Enter 'Number of those aged 16+ who are unemployed':  100000\n",
      "Enter 'HGV - Motorways':  100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPredicted Price: £15954600.08\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to make another prediction? (y/n):  n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def predict_with_dynamic_features(input_features):\n",
    "    # Loading default values\n",
    "    data_defaults = pd.read_excel('../Data/Output/combined_default_values.xlsx')\n",
    "    default_data = data_defaults.set_index('feature').T.to_dict('records')[0]\n",
    "    \n",
    "    # Updating defaults with dynamic values from input_features\n",
    "    for key, value in input_features.items():\n",
    "        if key in default_data:\n",
    "            default_data[key] = value\n",
    "    \n",
    "    # Creating DataFrame from updated defaults\n",
    "    updated_input_df = pd.DataFrame([default_data])\n",
    "    \n",
    "    # Preprocessing steps\n",
    "    ETL_first_stage_pipeline = joblib.load('../Models/first_stage_pipeline.pkl')\n",
    "    ETL_first_stage_output = ETL_first_stage_pipeline.transform(updated_input_df)\n",
    "    ETL_second_stage_pipeline = joblib.load('../Models/second_stage_pipeline.pkl')\n",
    "    ETL_second_stage_output = ETL_second_stage_pipeline.transform(ETL_first_stage_output)\n",
    "    \n",
    "    # Filling NaN values\n",
    "    # Calculating fill values dynamically from the same dataset\n",
    "    null_data_fix = pd.read_excel('../Data/Output/ETL_second_stage_output.xlsx')\n",
    "    price_change_fields = ['AveragePrice_PctChange', 'DetachedPrice_PctChange', 'SemiDetachedPrice_PctChange', 'TerracedPrice_PctChange', 'FlatPrice_PctChange']\n",
    "    fill_values = null_data_fix[price_change_fields].mean().to_dict()\n",
    "    ETL_second_stage_output.fillna(value=fill_values, inplace=True)\n",
    "    \n",
    "    # Preparing data for prediction\n",
    "    final_combined_features_df = pd.read_excel('../Data/Output/final_combined_features.xlsx')\n",
    "    ETL_selected_features = final_combined_features_df['Feature'].tolist()\n",
    "    ETL_X = ETL_second_stage_output[ETL_selected_features]\n",
    "    \n",
    "    # Loading model and making predictions\n",
    "    rf_model = joblib.load('../Models/RandomForest_house_price_prediction_model.pkl')\n",
    "    predictions = rf_model.predict(ETL_X)\n",
    "    \n",
    "    # Scaling\n",
    "    pipeline = joblib.load('../Models/second_stage_pipeline.pkl')\n",
    "    price_scaler = pipeline.named_steps['scale_normalize'].named_transformers_['robust_scaler_price']\n",
    "    predictions_unscaled = price_scaler.inverse_transform(predictions.reshape(-1, 1)).flatten()\n",
    "\n",
    "    return predictions_unscaled[0]\n",
    "while True:\n",
    "    # Interactive input\n",
    "    input_features = {\n",
    "        'Level 4 qualifications and above': int(input(\"Enter 'Level 4 qualifications and above': \")),\n",
    "        '20-40': int(input(\"Enter '20-40' population: \")),\n",
    "        'Number of those aged 16+ who are unemployed': int(input(\"Enter 'Number of those aged 16+ who are unemployed': \")),   \n",
    "        'HGV - Motorways': int(input(\"Enter 'HGV - Motorways': \"))\n",
    "    }\n",
    "\n",
    "    result = predict_with_dynamic_features(input_features)\n",
    "\n",
    "    # Displaying the result\n",
    "    print(f\"\\033[1mPredicted Price: £{result:.2f}\\033[0m\")\n",
    "\n",
    "    continue_predicting = input(\"\\nDo you want to make another prediction? (y/n): \")\n",
    "    if continue_predicting.lower() != 'y':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f870831b-957b-44e2-afa9-efb32b2cf955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
